{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['train_dir'] = 'trained_models/okay_nabu_no_end_depthwise'\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_positive',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_negative',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/english_speech_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/non_english_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 3,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# config['features'] = [\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "#             'sampling_weight': 150,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#     ]\n",
    "# features_directory = '/Volumes/MachineLearning/multilingual_stuff/mswc_features/'\n",
    "# words = os.listdir(features_directory)\n",
    "\n",
    "# words = [x for x in words if not x.startswith('.')]\n",
    "\n",
    "# for index, word in enumerate(words):\n",
    "#     config['features'].append({\n",
    "#             'features_dir': os.path.join(features_directory, word),\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': True,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",        \n",
    "#     })\n",
    "\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [10000]#[20000,20000,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [5]\n",
    "\n",
    "config['learning_rates'] = [0.0001]#[0.0005,0.0002,0.0001]#[0.002, 0.001, 0.0005,0.0002] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 256\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [7]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1490   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "config['target_minimization'] = 0.25\n",
    "config['maximization_metric'] = 'recall'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 4497821 spectrograms representing 12787.0 hours of audio\n",
      "INFO:absl:validation mode has 19909 spectrograms representing 27.5 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 30258 spectrograms representing 33.2 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "2024-04-19 15:42:38.235770: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-04-19 15:42:38.235794: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-19 15:42:38.235801: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-19 15:42:38.235832: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-19 15:42:38.235848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 74\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_conv2d_18_conv2d_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/okay_nabu_no_end_depthwise/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "2024-04-19 15:42:43.976807: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-19 15:42:43.976824: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-19 15:42:43.977420: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/okay_nabu_no_end_depthwise/stream_state_internal\n",
      "2024-04-19 15:42:43.983762: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-19 15:42:43.983775: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/okay_nabu_no_end_depthwise/stream_state_internal\n",
      "2024-04-19 15:42:43.993673: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-19 15:42:43.999777: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-19 15:42:44.133028: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/okay_nabu_no_end_depthwise/stream_state_internal\n",
      "2024-04-19 15:42:44.179205: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 201785 microseconds.\n",
      "2024-04-19 15:42:44.229561: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-19 15:42:44.436612: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436638: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436641: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436643: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436645: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436647: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436648: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436650: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436652: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436663: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436665: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436667: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436677: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436679: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436680: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436682: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436684: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436818: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436820: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436821: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436823: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436825: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436827: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-19 15:42:44.436829: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 71, Total Ops 198, % non-converted = 35.86 %\n",
      " * 70 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   70 occurrences  (f32: 58, i32: 12)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 15)\n",
      "  (f32: 19)\n",
      "  (f32: 11)\n",
      "  (f32: 1)\n",
      "  (f32: 12)\n",
      "  (f32: 2)\n",
      "  (f32: 12)\n",
      "  (: 24)\n",
      "2024-04-19 15:42:44.440299: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.039 M  ops, equivalently 0.020 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-04-19 15:43:29.611491: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.039 M  ops, equivalently 0.020 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing set\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.977023; recall = 0.938953; precision = 0.993846; fpr = 0.00304414; fnr = 0.0610465 (1000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.976512; recall = 0.933232; precision = 0.995146; fpr = 0.00223547; fnr = 0.0667678 (2000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.975342; recall = 0.932596; precision = 0.992505; fpr = 0.00348779; fnr = 0.0674044 (3000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.975506; recall = 0.934816; precision = 0.989448; fpr = 0.00482017; fnr = 0.065184 (4000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974205; recall = 0.931349; precision = 0.989671; fpr = 0.004769; fnr = 0.0686513 (5000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974504; recall = 0.931646; precision = 0.990312; fpr = 0.00447094; fnr = 0.0683544 (6000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974718; recall = 0.932784; precision = 0.989876; fpr = 0.00468584; fnr = 0.067216 (7000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973878; recall = 0.928708; precision = 0.990597; fpr = 0.00426558; fnr = 0.0712917 (8000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974003; recall = 0.92891; precision = 0.991329; fpr = 0.00396891; fnr = 0.07109 (9000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973703; recall = 0.927567; precision = 0.991506; fpr = 0.00386387; fnr = 0.0724328 (10000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973821; recall = 0.927644; precision = 0.992319; fpr = 0.00352304; fnr = 0.0723557 (11000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973502; recall = 0.927511; precision = 0.991925; fpr = 0.00373692; fnr = 0.0724893 (12000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.97331; recall = 0.927281; precision = 0.991826; fpr = 0.00380053; fnr = 0.0727189 (13000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973645; recall = 0.928923; precision = 0.991545; fpr = 0.0039657; fnr = 0.0710769 (14000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973735; recall = 0.928843; precision = 0.991654; fpr = 0.00389533; fnr = 0.0711565 (15000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973689; recall = 0.928773; precision = 0.991573; fpr = 0.00393258; fnr = 0.0712272 (16000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973943; recall = 0.929368; precision = 0.991689; fpr = 0.00387597; fnr = 0.070632 (17000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.973946; recall = 0.929242; precision = 0.991591; fpr = 0.00390463; fnr = 0.0707579 (18000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974317; recall = 0.930162; precision = 0.991689; fpr = 0.00385372; fnr = 0.0698377 (19000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974251; recall = 0.92988; precision = 0.991602; fpr = 0.00388118; fnr = 0.0701196 (20000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974335; recall = 0.929759; precision = 0.991829; fpr = 0.00376367; fnr = 0.0702414 (21000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974274; recall = 0.929781; precision = 0.991776; fpr = 0.0037997; fnr = 0.0702189 (22000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974523; recall = 0.930401; precision = 0.991695; fpr = 0.00382397; fnr = 0.0695985 (23000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974584; recall = 0.930383; precision = 0.991755; fpr = 0.00378529; fnr = 0.069617 (24000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974801; recall = 0.930972; precision = 0.991829; fpr = 0.0037529; fnr = 0.0690285 (25000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974809; recall = 0.930885; precision = 0.992024; fpr = 0.00366762; fnr = 0.0691147 (26000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974742; recall = 0.930899; precision = 0.991978; fpr = 0.00370145; fnr = 0.0691011 (27000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974787; recall = 0.930978; precision = 0.992033; fpr = 0.00367569; fnr = 0.0690216 (28000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974622; recall = 0.930381; precision = 0.992074; fpr = 0.00365057; fnr = 0.0696189 (29000 out of 30258)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.974301; recall = 0.929351; precision = 0.99223; fpr = 0.00358084; fnr = 0.0706489 (30000 out of 30258)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 97.4420%; recall = 92.9696%; precision = 99.2187%; fpr = 0.3598%; fnr = 7.0304%; (N=30258.0)\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 6.0; false accepts per hour = 1.125\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 0 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "wide_matchbox \\\n",
    "--activation 'relu' \\\n",
    "--dropout 0.0 \\\n",
    "--ds_filters '40, 20, 20, 20, 40, 40' \\\n",
    "--ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "--ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "--ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# ds_tc_resnet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --ds_filters '96, 48, 48, 48, 96, 96' \\\n",
    "# --ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# inception \\\n",
    "# --cnn1_filters '32' \\\n",
    "# --cnn1_kernel_sizes '5' \\\n",
    "# --cnn1_subspectral_groups '1' \\\n",
    "# --cnn2_filters1 '24,24,24' \\\n",
    "# --cnn2_filters2 '32,64,96' \\\n",
    "# --cnn2_kernel_sizes '3,5,5' \\\n",
    "# --cnn2_subspectral_groups '1,1,1' \\\n",
    "# --cnn2_dilation '1,1,1' \\\n",
    "# --dropout 0.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
