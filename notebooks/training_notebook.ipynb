{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['train_dir'] = 'trained_models/testing_outputs'\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_positive',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_negative',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/english_speech_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/non_english_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 3,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [5000]#[20000, 20000,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [20]#[2, 3, 4, 5]\n",
    "\n",
    "config['learning_rates'] = [0.0001] #[0.002, 0.001, 0.0005,0.0002] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 256\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [7]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1490   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "config['target_minimization'] = 0.25\n",
    "config['maximization_metric'] = 'recall'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 4497821 spectrograms representing 12787.0 hours of audio\n",
      "INFO:absl:validation mode has 19909 spectrograms representing 27.5 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 36543 spectrograms representing 36.6 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "2024-04-11 07:58:44.311299: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-04-11 07:58:44.311329: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-11 07:58:44.311339: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-11 07:58:44.311374: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-11 07:58:44.311392: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(256, 196, 40)]             0         []                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (256, 196, 1, 40)            0         ['input_1[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stream (Stream)             (256, 186, 1, 40)            440       ['tf.expand_dims[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (256, 186, 1, 40)            1600      ['stream[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (256, 186, 1, 40)            160       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (256, 186, 1, 40)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " stream_2 (Stream)           (256, 174, 1, 40)            520       ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (256, 174, 1, 20)            800       ['stream_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (256, 174, 1, 20)            80        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stream_1 (Stream)           (256, 174, 1, 40)            520       ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (256, 174, 1, 20)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (256, 186, 1, 20)            800       ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (256, 174, 1, 20)            800       ['stream_1[0][0]']            \n",
      "                                                                                                  \n",
      " stream_3 (Stream)           (256, 162, 1, 20)            260       ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (256, 186, 1, 20)            80        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (256, 174, 1, 20)            80        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (256, 162, 1, 20)            400       ['stream_3[0][0]']            \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (256, 186, 1, 20)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (256, 174, 1, 20)            0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (256, 162, 1, 20)            80        ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " strided_drop (StridedDrop)  (256, 162, 1, 20)            0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " strided_drop_1 (StridedDro  (256, 162, 1, 20)            0         ['activation_2[0][0]']        \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (256, 162, 1, 20)            0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (256, 162, 1, 60)            0         ['strided_drop[0][0]',        \n",
      "                                                                     'strided_drop_1[0][0]',      \n",
      "                                                                     'activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (256, 162, 1, 20)            1200      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (256, 162, 1, 20)            80        ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (256, 162, 1, 20)            0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_5 (Stream)           (256, 148, 1, 20)            300       ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (256, 148, 1, 20)            400       ['stream_5[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (256, 148, 1, 20)            80        ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " stream_4 (Stream)           (256, 148, 1, 20)            300       ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (256, 148, 1, 20)            0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (256, 162, 1, 20)            400       ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (256, 148, 1, 20)            400       ['stream_4[0][0]']            \n",
      "                                                                                                  \n",
      " stream_6 (Stream)           (256, 134, 1, 20)            300       ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (256, 162, 1, 20)            80        ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (256, 148, 1, 20)            80        ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (256, 134, 1, 20)            400       ['stream_6[0][0]']            \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (256, 162, 1, 20)            0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (256, 148, 1, 20)            0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (256, 134, 1, 20)            80        ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " strided_drop_2 (StridedDro  (256, 134, 1, 20)            0         ['activation_6[0][0]']        \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_3 (StridedDro  (256, 134, 1, 20)            0         ['activation_7[0][0]']        \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (256, 134, 1, 20)            0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (256, 134, 1, 60)            0         ['strided_drop_2[0][0]',      \n",
      " )                                                                   'strided_drop_3[0][0]',      \n",
      "                                                                     'activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (256, 134, 1, 20)            1200      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (256, 134, 1, 20)            80        ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (256, 134, 1, 20)            0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " stream_8 (Stream)           (256, 118, 1, 20)            340       ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (256, 118, 1, 20)            400       ['stream_8[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (256, 118, 1, 20)            80        ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " stream_7 (Stream)           (256, 118, 1, 20)            340       ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (256, 118, 1, 20)            0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (256, 134, 1, 20)            400       ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (256, 118, 1, 20)            400       ['stream_7[0][0]']            \n",
      "                                                                                                  \n",
      " stream_9 (Stream)           (256, 102, 1, 20)            340       ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (256, 134, 1, 20)            80        ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (256, 118, 1, 20)            80        ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (256, 102, 1, 20)            400       ['stream_9[0][0]']            \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (256, 134, 1, 20)            0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (256, 118, 1, 20)            0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (256, 102, 1, 20)            80        ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " strided_drop_4 (StridedDro  (256, 102, 1, 20)            0         ['activation_11[0][0]']       \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_5 (StridedDro  (256, 102, 1, 20)            0         ['activation_12[0][0]']       \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (256, 102, 1, 20)            0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (256, 102, 1, 60)            0         ['strided_drop_4[0][0]',      \n",
      " )                                                                   'strided_drop_5[0][0]',      \n",
      "                                                                     'activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (256, 102, 1, 20)            1200      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (256, 102, 1, 20)            80        ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (256, 102, 1, 20)            0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " stream_10 (Stream)          (256, 74, 1, 20)             580       ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (256, 74, 1, 40)             800       ['stream_10[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (256, 74, 1, 40)             160       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (256, 74, 1, 40)             0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " stream_11 (Stream)          (256, 74, 1, 40)             40        ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (256, 74, 1, 40)             1600      ['stream_11[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (256, 74, 1, 40)             160       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (256, 74, 1, 40)             0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " stream_12 (Stream)          (256, 1, 1, 40)              0         ['activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (256, 1, 1, 1)               40        ['stream_12[0][0]']           \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOp  (256, 1)                     0         ['conv2d_18[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (256, 1)                     0         ['tf.compat.v1.squeeze[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19600 (76.56 KB)\n",
      "Trainable params: 18760 (73.28 KB)\n",
      "Non-trainable params: 840 (3.28 KB)\n",
      "__________________________________________________________________________________________________\n",
      "INFO:absl:None\n",
      "2024-04-11 07:58:46.461513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "INFO:absl:Step #500: rate 0.000100, accuracy 87.75%, recall 37.71%, precision 51.22%, cross entropy 0.402407\n",
      "INFO:absl:Step 500 (nonstreaming): Validation accuracy = 74.39%, recall = 53.60%, precision = 91.92%, fpr = 4.73%, fnr = 46.40%, ambient false positives = 23, estimated false positives per hour = 4.31137, loss = 0.53002, auc = 0.83652,\n",
      "INFO:absl:So far the best minimization quantity is 4.311 with best maximization quantity of 53.59936%\n",
      "INFO:absl:Step #1000: rate 0.000100, accuracy 91.43%, recall 34.86%, precision 92.24%, cross entropy 0.250155\n",
      "INFO:absl:Step 1000 (nonstreaming): Validation accuracy = 79.74%, recall = 62.68%, precision = 95.25%, fpr = 3.14%, fnr = 37.32%, ambient false positives = 17, estimated false positives per hour = 3.18666, loss = 0.49238, auc = 0.88042,\n",
      "INFO:absl:So far the best minimization quantity is 3.187 with best maximization quantity of 62.68298%\n",
      "INFO:absl:Step #1500: rate 0.000100, accuracy 91.34%, recall 32.55%, precision 96.96%, cross entropy 0.245089\n",
      "INFO:absl:Step 1500 (nonstreaming): Validation accuracy = 79.96%, recall = 61.71%, precision = 97.31%, fpr = 1.71%, fnr = 38.29%, ambient false positives = 11, estimated false positives per hour = 2.06196, loss = 0.50149, auc = 0.89870,\n",
      "INFO:absl:So far the best minimization quantity is 2.062 with best maximization quantity of 61.71045%\n",
      "INFO:absl:Step #2000: rate 0.000100, accuracy 91.46%, recall 33.04%, precision 98.20%, cross entropy 0.242684\n",
      "INFO:absl:Step 2000 (nonstreaming): Validation accuracy = 81.31%, recall = 64.11%, precision = 97.84%, fpr = 1.42%, fnr = 35.89%, ambient false positives = 6, estimated false positives per hour = 1.12470, loss = 0.48438, auc = 0.91585,\n",
      "INFO:absl:So far the best minimization quantity is 1.125 with best maximization quantity of 64.10668%\n",
      "INFO:absl:Step #2500: rate 0.000100, accuracy 91.68%, recall 33.92%, precision 98.71%, cross entropy 0.237596\n",
      "INFO:absl:Step 2500 (nonstreaming): Validation accuracy = 81.57%, recall = 64.34%, precision = 98.27%, fpr = 1.14%, fnr = 35.66%, ambient false positives = 6, estimated false positives per hour = 1.12470, loss = 0.48477, auc = 0.92905,\n",
      "INFO:absl:So far the best minimization quantity is 1.125 with best maximization quantity of 64.33728%\n",
      "INFO:absl:Step #3000: rate 0.000100, accuracy 91.95%, recall 35.85%, precision 98.98%, cross entropy 0.228688\n",
      "INFO:absl:Step 3000 (nonstreaming): Validation accuracy = 78.15%, recall = 56.75%, precision = 99.35%, fpr = 0.37%, fnr = 43.25%, ambient false positives = 1, estimated false positives per hour = 0.18745, loss = 0.57874, auc = 0.93745,\n",
      "INFO:absl:So far the best minimization quantity is 0.187 with best maximization quantity of 56.74754%\n",
      "INFO:absl:Step #3500: rate 0.000100, accuracy 92.11%, recall 37.66%, precision 99.04%, cross entropy 0.221441\n",
      "INFO:absl:Step 3500 (nonstreaming): Validation accuracy = 82.84%, recall = 66.65%, precision = 98.65%, fpr = 0.92%, fnr = 33.35%, ambient false positives = 3, estimated false positives per hour = 0.56235, loss = 0.45441, auc = 0.95199,\n",
      "INFO:absl:So far the best minimization quantity is 0.187 with best maximization quantity of 56.74754%\n",
      "INFO:absl:Step #4000: rate 0.000100, accuracy 92.51%, recall 40.20%, precision 99.23%, cross entropy 0.210710\n",
      "INFO:absl:Step 4000 (nonstreaming): Validation accuracy = 82.19%, recall = 64.97%, precision = 99.22%, fpr = 0.51%, fnr = 35.03%, ambient false positives = 2, estimated false positives per hour = 0.37490, loss = 0.47452, auc = 0.95942,\n",
      "INFO:absl:So far the best minimization quantity is 0.187 with best maximization quantity of 56.74754%\n",
      "INFO:absl:Step #4500: rate 0.000100, accuracy 92.96%, recall 43.67%, precision 99.39%, cross entropy 0.200874\n",
      "INFO:absl:Step 4500 (nonstreaming): Validation accuracy = 84.44%, recall = 69.59%, precision = 99.09%, fpr = 0.64%, fnr = 30.41%, ambient false positives = 5, estimated false positives per hour = 0.93725, loss = 0.40921, auc = 0.96569,\n",
      "INFO:absl:So far the best minimization quantity is 0.187 with best maximization quantity of 56.74754%\n",
      "INFO:absl:Step #5000: rate 0.000100, accuracy 93.30%, recall 46.76%, precision 99.47%, cross entropy 0.191652\n",
      "INFO:absl:Step 5000 (nonstreaming): Validation accuracy = 82.58%, recall = 65.62%, precision = 99.39%, fpr = 0.40%, fnr = 34.38%, ambient false positives = 3, estimated false positives per hour = 0.56235, loss = 0.47891, auc = 0.96564,\n",
      "INFO:absl:So far the best minimization quantity is 0.187 with best maximization quantity of 56.74754%\n",
      "INFO:absl:Last weights on testing set: accuracy = 90.5290%; recall = 65.8510%; precision = 99.1543%; fpr = 0.2107%; fnr = 34.1490%; (N=36543.0)\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 0\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 74\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_1_conv2d_37_conv2d_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/testing_outputs/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "2024-04-11 08:25:35.095938: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-11 08:25:35.095963: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-11 08:25:35.097062: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/testing_outputs/stream_state_internal\n",
      "2024-04-11 08:25:35.103683: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-11 08:25:35.103701: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/testing_outputs/stream_state_internal\n",
      "2024-04-11 08:25:35.117856: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-11 08:25:35.124037: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-11 08:25:35.264870: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/testing_outputs/stream_state_internal\n",
      "2024-04-11 08:25:35.324824: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 227762 microseconds.\n",
      "2024-04-11 08:25:35.385358: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-11 08:25:35.617713: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617734: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617737: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617740: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617742: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617744: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617746: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617748: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617749: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617757: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617759: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617761: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617782: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617784: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617786: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617788: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617790: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617933: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617935: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617936: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617938: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617940: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617942: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-11 08:25:35.617944: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 72, Total Ops 200, % non-converted = 36.00 %\n",
      " * 71 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   71 occurrences  (f32: 59, i32: 12)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 15)\n",
      "  (f32: 19)\n",
      "  (f32: 12)\n",
      "  (f32: 1)\n",
      "  (f32: 12)\n",
      "  (f32: 2)\n",
      "  (f32: 12)\n",
      "  (: 24)\n",
      "2024-04-11 08:25:35.622403: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.040 M  ops, equivalently 0.020 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-04-11 08:26:21.968534: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.040 M  ops, equivalently 0.020 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing set\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.876124; recall = 0.533074; precision = 0.971631; fpr = 0.00537634; fnr = 0.466926 (1000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.877561; recall = 0.54717; precision = 0.983051; fpr = 0.00339905; fnr = 0.45283 (2000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.878041; recall = 0.547859; precision = 0.984163; fpr = 0.00317173; fnr = 0.452141 (3000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.875531; recall = 0.549632; precision = 0.986799; fpr = 0.00274631; fnr = 0.450368 (4000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.875825; recall = 0.549483; precision = 0.98543; fpr = 0.00301618; fnr = 0.450517 (5000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.877687; recall = 0.552387; precision = 0.986711; fpr = 0.00273473; fnr = 0.447613 (6000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.878017; recall = 0.554968; precision = 0.988701; fpr = 0.0023488; fnr = 0.445032 (7000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.877765; recall = 0.554734; precision = 0.988477; fpr = 0.0023989; fnr = 0.445266 (8000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.879125; recall = 0.561195; precision = 0.988464; fpr = 0.00243977; fnr = 0.438805 (9000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880212; recall = 0.564736; precision = 0.98838; fpr = 0.00246914; fnr = 0.435264 (10000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881284; recall = 0.564953; precision = 0.988166; fpr = 0.00248602; fnr = 0.435047 (11000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881593; recall = 0.566966; precision = 0.988673; fpr = 0.00239507; fnr = 0.433034 (12000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881855; recall = 0.569069; precision = 0.988619; fpr = 0.0024236; fnr = 0.430931 (13000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881866; recall = 0.570374; precision = 0.989031; fpr = 0.00235133; fnr = 0.429626 (14000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881541; recall = 0.570343; precision = 0.989792; fpr = 0.0021976; fnr = 0.429657 (15000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881257; recall = 0.569754; precision = 0.988831; fpr = 0.00240343; fnr = 0.430246 (16000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.88136; recall = 0.568793; precision = 0.988684; fpr = 0.00242072; fnr = 0.431207 (17000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881284; recall = 0.56835; precision = 0.98787; fpr = 0.00258969; fnr = 0.43165 (18000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881217; recall = 0.568235; precision = 0.987834; fpr = 0.00259796; fnr = 0.431765 (19000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880656; recall = 0.566685; precision = 0.987781; fpr = 0.00260631; fnr = 0.433315 (20000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881101; recall = 0.567862; precision = 0.98807; fpr = 0.00254686; fnr = 0.432138 (21000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880869; recall = 0.567477; precision = 0.988033; fpr = 0.00255675; fnr = 0.432523 (22000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880875; recall = 0.567351; precision = 0.988268; fpr = 0.00250522; fnr = 0.432649 (23000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880422; recall = 0.565806; precision = 0.987654; fpr = 0.00262902; fnr = 0.434194 (24000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880405; recall = 0.565865; precision = 0.987896; fpr = 0.0025793; fnr = 0.434135 (25000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880774; recall = 0.56615; precision = 0.98834; fpr = 0.00247838; fnr = 0.43385 (26000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880893; recall = 0.566621; precision = 0.988544; fpr = 0.00243766; fnr = 0.433379 (27000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880969; recall = 0.567001; precision = 0.988503; fpr = 0.0024487; fnr = 0.432999 (28000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881177; recall = 0.567351; precision = 0.988674; fpr = 0.00241089; fnr = 0.432649 (29000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.881204; recall = 0.567291; precision = 0.988617; fpr = 0.00242153; fnr = 0.432709 (30000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.88123; recall = 0.568676; precision = 0.988629; fpr = 0.00243449; fnr = 0.431324 (31000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880941; recall = 0.568038; precision = 0.987778; fpr = 0.00261556; fnr = 0.431962 (32000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880428; recall = 0.567577; precision = 0.987401; fpr = 0.0027054; fnr = 0.432423 (33000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.88018; recall = 0.567167; precision = 0.987023; fpr = 0.0027881; fnr = 0.432833 (34000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880203; recall = 0.566639; precision = 0.987182; fpr = 0.0027465; fnr = 0.433361 (35000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.880281; recall = 0.56814; precision = 0.987606; fpr = 0.00267349; fnr = 0.43186 (36000 out of 36543)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 88.0196%; recall = 56.8047%; precision = 98.7620%; fpr = 0.2672%; fnr = 43.1953%; (N=36543.0)\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 1.0; false accepts per hour = 0.1875\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "wide_matchbox \\\n",
    "--activation 'relu' \\\n",
    "--dropout 0.0 \\\n",
    "--ds_filters '40, 20, 20, 20, 40, 40' \\\n",
    "--ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "--ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "--ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# ds_tc_resnet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --ds_filters '96, 48, 48, 48, 96, 96' \\\n",
    "# --ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# inception \\\n",
    "# --cnn1_filters '32' \\\n",
    "# --cnn1_kernel_sizes '5' \\\n",
    "# --cnn1_subspectral_groups '1' \\\n",
    "# --cnn2_filters1 '24,24,24' \\\n",
    "# --cnn2_filters2 '32,64,96' \\\n",
    "# --cnn2_kernel_sizes '3,5,5' \\\n",
    "# --cnn2_subspectral_groups '1,1,1' \\\n",
    "# --cnn2_dilation '1,1,1' \\\n",
    "# --dropout 0.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
