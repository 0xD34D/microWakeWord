{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from microwakeword.feature_generation import ClipsHandler\n",
    "\n",
    "config = {}\n",
    "\n",
    "# config['train_dir'] = 'trained_models/test_new_formulation'\n",
    "config['train_dir'] = 'trained_models/hey_mycroft_mixednet_real_positives2'\n",
    "\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/hey_mycroft/positive',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/hey_mycroft/positive_real_samples',\n",
    "            'sampling_weight': 0.4,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/piper-sample-generator/output/hey_mycroft_split2/train',\n",
    "            'input_glob': '*.wav',\n",
    "            # 'impulse_paths': ['mit_rirs/'], \n",
    "            'impulse_paths': ['/Volumes/MachineLearning/audio_samples/background_noise_samples/wav_16k/bird_rir_all_channels_16k'], \n",
    "            'background_paths': ['/Volumes/MachineLearning/audio_samples/background_noise_samples/background_clips_for_mixing'], \n",
    "            'augmentation_probabilities': {\n",
    "                    \"SevenBandParametricEQ\": 0.1,\n",
    "                    \"TanhDistortion\": 0.1,\n",
    "                    \"PitchShift\": 0.1,\n",
    "                    \"BandStopFilter\": 0.1,\n",
    "                    \"AddColorNoise\": 0.25,\n",
    "                    \"AddBackgroundNoise\": 0.75,\n",
    "                    \"Gain\": 1.0,\n",
    "                    \"RIR\": 0.5,\n",
    "                },\n",
    "            'augmented_duration_s': 2.99,\n",
    "            'max_start_time_from_right_s': None,\n",
    "            'max_jitter_s': 0.1,\n",
    "            'max_clip_duration_s': 1.39,   \n",
    "            'min_clip_duration_s': None,\n",
    "            'sampling_weight': 0.2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"clips\",            \n",
    "        },\n",
    "        # {\n",
    "        #     'features_dir': '/Volumes/MachineLearning/training_data/alexa/old_negative',\n",
    "        #     'sampling_weight': 0,\n",
    "        #     'penalty_weight': 0.1,\n",
    "        #     'truth': False,\n",
    "        #     'truncation_strategy': 'truncate_start',\n",
    "        #     'type': \"mmap\",            \n",
    "        # },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/speech_background_new',\n",
    "            'sampling_weight': 4,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# config['features'] = [\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "#             'sampling_weight': 150,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#     ]\n",
    "# features_directory = '/Volumes/MachineLearning/multilingual_stuff/mswc_features/'\n",
    "# words = os.listdir(features_directory)\n",
    "\n",
    "# words = [x for x in words if not x.startswith('.')]\n",
    "\n",
    "# for index, word in enumerate(words):\n",
    "#     config['features'].append({\n",
    "#             'features_dir': os.path.join(features_directory, word),\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': True,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",        \n",
    "#     })\n",
    "\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [10000]#,15000]#,15000]#[15000,15000,15000]#[20000,20000]#,20000]#[20000,20000,20000]#,20000]#20000]#,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [8,5]#7.5,10]#[1,1.5,2]\n",
    "\n",
    "config['learning_rates'] = [0.0001]#[0.001, 0.0005,0.0005,0.0002]#,0.001] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 128\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [10]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [0]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [4]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1010   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "# config['minimization_metric'] = None  # Set to None to disable\n",
    "config['target_minimization'] = 1.0\n",
    "config['maximization_metric'] = 'recall'\n",
    "# config['maximization_metric'] = 'recall_at_no_faph'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 1077428 spectrograms representing 1355.9 hours of audio\n",
      "INFO:absl:validation mode has 5206 spectrograms representing 4.3 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 5207 spectrograms representing 4.3 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "2024-05-07 06:09:55.591978: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-05-07 06:09:55.592020: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-05-07 06:09:55.592026: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-05-07 06:09:55.592089: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-07 06:09:55.592105: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 2\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 6\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 8\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(128, 100, 40)]             0         []                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (128, 100, 1, 40)            0         ['input_1[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stream (Stream)             (128, 98, 1, 32)             3840      ['tf.expand_dims[0][0]']      \n",
      "                                                                                                  \n",
      " activation (Activation)     (128, 98, 1, 32)             0         ['stream[0][0]']              \n",
      "                                                                                                  \n",
      " stream_1 (Stream)           (128, 98, 1, 32)             0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (128, 96, 1, 32)             128       ['stream_1[0][0]']            \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (128, 96, 1, 32)             1024      ['depthwise_conv2d[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (128, 96, 1, 32)             128       ['conv2d_1[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (128, 96, 1, 32)             0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " stream_2 (Stream)           (128, 96, 1, 32)             0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)       [(128, 96, 1, 16),           0         ['stream_2[0][0]']            \n",
      "                              (128, 96, 1, 16)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep (StridedKeep)  (128, 96, 1, 16)             0         ['tf.split[0][0]']            \n",
      "                                                                                                  \n",
      " strided_keep_1 (StridedKee  (128, 96, 1, 16)             0         ['tf.split[0][1]']            \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (128, 94, 1, 16)             64        ['strided_keep[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (128, 92, 1, 16)             96        ['strided_keep_1[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop (StridedDrop)  (128, 92, 1, 16)             0         ['depthwise_conv2d_1[0][0]']  \n",
      "                                                                                                  \n",
      " strided_drop_1 (StridedDro  (128, 92, 1, 16)             0         ['depthwise_conv2d_2[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (128, 92, 1, 32)             0         ['strided_drop[0][0]',        \n",
      "                                                                     'strided_drop_1[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (128, 96, 1, 48)             1536      ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (128, 92, 1, 48)             1536      ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (128, 96, 1, 48)             192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (128, 92, 1, 48)             192       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (128, 96, 1, 48)             0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (128, 92, 1, 48)             0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " strided_drop_2 (StridedDro  (128, 92, 1, 48)             0         ['activation_2[0][0]']        \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (128, 92, 1, 48)             0         ['activation_3[0][0]',        \n",
      " Lambda)                                                             'strided_drop_2[0][0]']      \n",
      "                                                                                                  \n",
      " stream_3 (Stream)           (128, 92, 1, 48)             0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)     [(128, 92, 1, 16),           0         ['stream_3[0][0]']            \n",
      "                              (128, 92, 1, 16),                                                   \n",
      "                              (128, 92, 1, 16)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_2 (StridedKee  (128, 92, 1, 16)             0         ['tf.split_1[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_3 (StridedKee  (128, 92, 1, 16)             0         ['tf.split_1[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_4 (StridedKee  (128, 92, 1, 16)             0         ['tf.split_1[0][2]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (128, 90, 1, 16)             64        ['strided_keep_2[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (128, 88, 1, 16)             96        ['strided_keep_3[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (128, 86, 1, 16)             128       ['strided_keep_4[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_3 (StridedDro  (128, 86, 1, 16)             0         ['depthwise_conv2d_3[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_4 (StridedDro  (128, 86, 1, 16)             0         ['depthwise_conv2d_4[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_5 (StridedDro  (128, 86, 1, 16)             0         ['depthwise_conv2d_5[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (128, 86, 1, 48)             0         ['strided_drop_3[0][0]',      \n",
      "                                                                     'strided_drop_4[0][0]',      \n",
      "                                                                     'strided_drop_5[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (128, 92, 1, 64)             3072      ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (128, 86, 1, 64)             3072      ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (128, 92, 1, 64)             256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (128, 86, 1, 64)             256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (128, 92, 1, 64)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (128, 86, 1, 64)             0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " strided_drop_6 (StridedDro  (128, 86, 1, 64)             0         ['activation_4[0][0]']        \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (128, 86, 1, 64)             0         ['activation_5[0][0]',        \n",
      " OpLambda)                                                           'strided_drop_6[0][0]']      \n",
      "                                                                                                  \n",
      " stream_4 (Stream)           (128, 86, 1, 64)             0         ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)     [(128, 86, 1, 16),           0         ['stream_4[0][0]']            \n",
      "                              (128, 86, 1, 16),                                                   \n",
      "                              (128, 86, 1, 16),                                                   \n",
      "                              (128, 86, 1, 16)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_5 (StridedKee  (128, 86, 1, 16)             0         ['tf.split_2[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_6 (StridedKee  (128, 86, 1, 16)             0         ['tf.split_2[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_7 (StridedKee  (128, 86, 1, 16)             0         ['tf.split_2[0][2]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_8 (StridedKee  (128, 86, 1, 16)             0         ['tf.split_2[0][3]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (128, 84, 1, 16)             64        ['strided_keep_5[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (Depthw  (128, 82, 1, 16)             96        ['strided_keep_6[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (Depthw  (128, 80, 1, 16)             128       ['strided_keep_7[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_9 (Depthw  (128, 78, 1, 16)             160       ['strided_keep_8[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_7 (StridedDro  (128, 78, 1, 16)             0         ['depthwise_conv2d_6[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_8 (StridedDro  (128, 78, 1, 16)             0         ['depthwise_conv2d_7[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_9 (StridedDro  (128, 78, 1, 16)             0         ['depthwise_conv2d_8[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_10 (StridedDr  (128, 78, 1, 16)             0         ['depthwise_conv2d_9[0][0]']  \n",
      " op)                                                                                              \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (128, 78, 1, 64)             0         ['strided_drop_7[0][0]',      \n",
      "                                                                     'strided_drop_8[0][0]',      \n",
      "                                                                     'strided_drop_9[0][0]',      \n",
      "                                                                     'strided_drop_10[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (128, 86, 1, 72)             4608      ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (128, 78, 1, 72)             4608      ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (128, 86, 1, 72)             288       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (128, 78, 1, 72)             288       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (128, 86, 1, 72)             0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (128, 78, 1, 72)             0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " strided_drop_11 (StridedDr  (128, 78, 1, 72)             0         ['activation_6[0][0]']        \n",
      " op)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (128, 78, 1, 72)             0         ['activation_7[0][0]',        \n",
      " OpLambda)                                                           'strided_drop_11[0][0]']     \n",
      "                                                                                                  \n",
      " stream_5 (Stream)           (128, 78, 1, 72)             0         ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.split_3 (TFOpLambda)     [(128, 78, 1, 36),           0         ['stream_5[0][0]']            \n",
      "                              (128, 78, 1, 36)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_9 (StridedKee  (128, 78, 1, 36)             0         ['tf.split_3[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_10 (StridedKe  (128, 78, 1, 36)             0         ['tf.split_3[0][1]']          \n",
      " ep)                                                                                              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_10 (Depth  (128, 62, 1, 36)             648       ['strided_keep_9[0][0]']      \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depth  (128, 50, 1, 36)             1080      ['strided_keep_10[0][0]']     \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " strided_drop_12 (StridedDr  (128, 50, 1, 36)             0         ['depthwise_conv2d_10[0][0]'] \n",
      " op)                                                                                              \n",
      "                                                                                                  \n",
      " strided_drop_13 (StridedDr  (128, 50, 1, 36)             0         ['depthwise_conv2d_11[0][0]'] \n",
      " op)                                                                                              \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (128, 50, 1, 72)             0         ['strided_drop_12[0][0]',     \n",
      "                                                                     'strided_drop_13[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (128, 50, 1, 72)             5184      ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (128, 50, 1, 72)             288       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (128, 50, 1, 72)             0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_6 (Stream)           (128, 1, 1, 72)              0         ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " stream_7 (Stream)           (128, 72)                    0         ['stream_6[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (128, 1)                     73        ['stream_7[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33193 (129.66 KB)\n",
      "Trainable params: 32249 (125.97 KB)\n",
      "Non-trainable params: 944 (3.69 KB)\n",
      "__________________________________________________________________________________________________\n",
      "INFO:absl:None\n",
      "2024-05-07 06:09:58.484922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "INFO:absl:Step #500: rate 0.000100, accuracy 99.83%, recall 97.30%, precision 99.86%, cross entropy 0.006560\n",
      "INFO:absl:Step 500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.29%, recall = 98.29%, precision = 100.00%, fpr = nan%, fnr = 1.71%, ambient false positives = 19, estimated false positives per hour = 3.56157, loss = 0.05878, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 3.562 with best maximization quantity of 98.29043%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #1000: rate 0.000100, accuracy 99.84%, recall 97.22%, precision 99.88%, cross entropy 0.005619\n",
      "INFO:absl:Step 1000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 97.62%, recall = 97.62%, precision = 100.00%, fpr = nan%, fnr = 2.38%, ambient false positives = 13, estimated false positives per hour = 2.43686, loss = 0.07951, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 2.437 with best maximization quantity of 97.61813%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #1500: rate 0.000100, accuracy 99.87%, recall 97.78%, precision 99.94%, cross entropy 0.004526\n",
      "INFO:absl:Step 1500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.73%, recall = 98.73%, precision = 100.00%, fpr = nan%, fnr = 1.27%, ambient false positives = 31, estimated false positives per hour = 5.81097, loss = 0.04408, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 2.437 with best maximization quantity of 97.61813%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #2000: rate 0.000100, accuracy 99.84%, recall 97.34%, precision 99.86%, cross entropy 0.005753\n",
      "INFO:absl:Step 2000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 97.89%, recall = 97.89%, precision = 100.00%, fpr = nan%, fnr = 2.11%, ambient false positives = 17, estimated false positives per hour = 3.18666, loss = 0.07441, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 2.437 with best maximization quantity of 97.61813%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #2500: rate 0.000100, accuracy 99.84%, recall 97.27%, precision 99.89%, cross entropy 0.006223\n",
      "INFO:absl:Step 2500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.14%, recall = 98.14%, precision = 100.00%, fpr = nan%, fnr = 1.86%, ambient false positives = 19, estimated false positives per hour = 3.56157, loss = 0.06839, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 2.437 with best maximization quantity of 97.61813%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #3000: rate 0.000100, accuracy 99.86%, recall 97.54%, precision 99.94%, cross entropy 0.005975\n",
      "INFO:absl:Step 3000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.46%, recall = 98.46%, precision = 100.00%, fpr = nan%, fnr = 1.54%, ambient false positives = 19, estimated false positives per hour = 3.56157, loss = 0.05635, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 2.437 with best maximization quantity of 97.61813%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #3500: rate 0.000100, accuracy 99.83%, recall 97.19%, precision 99.86%, cross entropy 0.005695\n",
      "INFO:absl:Step 3500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 96.00%, recall = 96.00%, precision = 100.00%, fpr = nan%, fnr = 4.00%, ambient false positives = 7, estimated false positives per hour = 1.31216, loss = 0.12666, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #4000: rate 0.000100, accuracy 99.85%, recall 97.34%, precision 99.94%, cross entropy 0.005721\n",
      "INFO:absl:Step 4000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 97.98%, recall = 97.98%, precision = 100.00%, fpr = nan%, fnr = 2.02%, ambient false positives = 12, estimated false positives per hour = 2.24941, loss = 0.07305, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #4500: rate 0.000100, accuracy 99.85%, recall 97.41%, precision 99.94%, cross entropy 0.005827\n",
      "INFO:absl:Step 4500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.46%, recall = 98.46%, precision = 100.00%, fpr = nan%, fnr = 1.54%, ambient false positives = 25, estimated false positives per hour = 4.68627, loss = 0.05493, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #5000: rate 0.000100, accuracy 99.85%, recall 97.56%, precision 99.86%, cross entropy 0.005276\n",
      "INFO:absl:Step 5000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 97.94%, recall = 97.94%, precision = 100.00%, fpr = nan%, fnr = 2.06%, ambient false positives = 12, estimated false positives per hour = 2.24941, loss = 0.07564, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #5500: rate 0.000100, accuracy 99.85%, recall 97.32%, precision 99.97%, cross entropy 0.005820\n",
      "INFO:absl:Step 5500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.52%, recall = 98.52%, precision = 100.00%, fpr = nan%, fnr = 1.48%, ambient false positives = 19, estimated false positives per hour = 3.56157, loss = 0.05686, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #6000: rate 0.000100, accuracy 99.87%, recall 97.66%, precision 99.97%, cross entropy 0.004784\n",
      "INFO:absl:Step 6000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.19%, recall = 98.19%, precision = 100.00%, fpr = nan%, fnr = 1.81%, ambient false positives = 11, estimated false positives per hour = 2.06196, loss = 0.06566, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #6500: rate 0.000100, accuracy 99.86%, recall 97.67%, precision 99.89%, cross entropy 0.005411\n",
      "INFO:absl:Step 6500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.67%, recall = 98.67%, precision = 100.00%, fpr = nan%, fnr = 1.33%, ambient false positives = 19, estimated false positives per hour = 3.56157, loss = 0.04720, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #7000: rate 0.000100, accuracy 99.85%, recall 97.49%, precision 99.89%, cross entropy 0.005523\n",
      "INFO:absl:Step 7000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.08%, recall = 98.08%, precision = 100.00%, fpr = nan%, fnr = 1.92%, ambient false positives = 11, estimated false positives per hour = 2.06196, loss = 0.06729, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #7500: rate 0.000100, accuracy 99.85%, recall 97.48%, precision 100.00%, cross entropy 0.005491\n",
      "INFO:absl:Step 7500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.92%, recall = 98.92%, precision = 100.00%, fpr = nan%, fnr = 1.08%, ambient false positives = 36, estimated false positives per hour = 6.74823, loss = 0.03967, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #8000: rate 0.000100, accuracy 99.86%, recall 97.51%, precision 99.97%, cross entropy 0.004833\n",
      "INFO:absl:Step 8000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.18%, recall = 98.18%, precision = 100.00%, fpr = nan%, fnr = 1.82%, ambient false positives = 16, estimated false positives per hour = 2.99921, loss = 0.06377, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #8500: rate 0.000100, accuracy 99.86%, recall 97.58%, precision 99.91%, cross entropy 0.005423\n",
      "INFO:absl:Step 8500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.64%, recall = 98.64%, precision = 100.00%, fpr = nan%, fnr = 1.36%, ambient false positives = 31, estimated false positives per hour = 5.81097, loss = 0.05104, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #9000: rate 0.000100, accuracy 99.84%, recall 97.27%, precision 99.89%, cross entropy 0.005971\n",
      "INFO:absl:Step 9000 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.60%, recall = 98.60%, precision = 100.00%, fpr = nan%, fnr = 1.40%, ambient false positives = 25, estimated false positives per hour = 4.68627, loss = 0.04951, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #9500: rate 0.000100, accuracy 99.88%, recall 97.93%, precision 99.91%, cross entropy 0.004785\n",
      "INFO:absl:Step 9500 (nonstreaming): Validation: recall at no faph = 0.000, accuracy = 98.29%, recall = 98.29%, precision = 100.00%, fpr = nan%, fnr = 1.71%, ambient false positives = 17, estimated false positives per hour = 3.18666, loss = 0.05998, auc = 0.00000,\n",
      "INFO:absl:So far the best minimization quantity is 1.312 with best maximization quantity of 96.00461%; no faph cutoff is 1.00\n",
      "Validation Batch #20: Accuracy = 0.998; Recall = 0.966; Precision = 0.999; Loss = 0.0066; Mini-Batch #305\r"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "mixednet \\\n",
    "--pointwise_filters \"32, 48, 64, 72, 72\" \\\n",
    "--repeat_in_block  \"1, 1, 1, 1, 1\" \\\n",
    "--mixconv_kernel_sizes \"[3], [3,5], [3,5,7], [3,5,7,9], [17,29]\" \\\n",
    "--residual_connection \"0,1,1,1,0\" \\\n",
    "--first_conv_filters 32\n",
    "# mixednet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --dropout_final_layer 0.0 \\\n",
    "# --ds_filters '32, 40, 40, 40, 48, 64' \\\n",
    "# --ds_filters2 '32, 32, 32, 32, 32, 32' \\\n",
    "# --ds_repeat '1, 2, 2, 2, 1, 0' \\\n",
    "# --ds_residual '0, 0, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '5, 7, 9, 11, 19, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_padding \"'valid','valid','valid','valid','valid','valid'\" \\\n",
    "# --ds_pool '1,1,1,1,1,1' \\\n",
    "# --max_pool '0' \\\n",
    "# --first_conv_filters 32\n",
    "# bc_wide_matchbox \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --dropout_final_layer 0.0 \\\n",
    "# --ds_filters '32, 24, 24, 24, 32, 32' \\\n",
    "# --ds_filters2 '32, 32, 32, 32, 32, 32' \\\n",
    "# --ds_repeat '1, 2, 2, 2, 1, 0' \\\n",
    "# --ds_residual '0, 0, 0, 0, 0, 0' \\\n",
    "# --ds_kernel_size '5, 7, 9, 11, 19, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_padding \"'valid','valid','valid','valid','valid','valid'\" \\\n",
    "# --ds_pool '1,1,1,1,1,1' \\\n",
    "# --max_pool '1' \\\n",
    "# --freq_stride '1,2,1,2,1,1' \\\n",
    "# --first_conv_filters 24\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
