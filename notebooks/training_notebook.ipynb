{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from microwakeword.feature_generation import ClipsHandler\n",
    "\n",
    "config = {}\n",
    "\n",
    "# config['train_dir'] = 'trained_models/test_new_formulation'\n",
    "config['train_dir'] = 'trained_models/alexa_spatial_attention2'\n",
    "\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': 'training_sets/alexa/fast_speech_eval',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'input_path': '/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/piper-sample-generator/output/alexa/fast_speech',\n",
    "            'input_glob': '*.wav',\n",
    "            # 'impulse_paths': ['mit_rirs/'], \n",
    "            'impulse_paths': ['/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/notebooks/mixing/rir'], \n",
    "            'background_paths': ['/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/notebooks/mixing/background_clips'], \n",
    "            'augmentation_probabilities': {\n",
    "                    \"SevenBandParametricEQ\": 0.1,\n",
    "                    \"TanhDistortion\": 0.1,\n",
    "                    \"PitchShift\": 0.1,\n",
    "                    \"BandStopFilter\": 0.1,\n",
    "                    \"AddColorNoise\": 0.25,\n",
    "                    \"AddBackgroundNoise\": 0.75,\n",
    "                    \"Gain\": 1.0,\n",
    "                    \"RIR\": 0.5,\n",
    "                },\n",
    "            'augmented_duration_s': 3.99,\n",
    "            'max_start_time_from_right_s': None,\n",
    "            'max_jitter_s': 0.03,\n",
    "            'min_jitter_s': None,#0.00,\n",
    "            'max_clip_duration_s': 1.1,   \n",
    "            'min_clip_duration_s': None,\n",
    "            'sampling_weight': 0.3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"clips\",   \n",
    "            'generate': False,\n",
    "            'generator_settings': {\n",
    "                'text': ['ə lɛk sə, ', 'ə lɛk sʌ, ', 'ɐ lɛk sə, ', 'ɐ lɛk sʌ, '],\n",
    "                'batch_size': 200,\n",
    "                'slerp_weights': [0.8],\n",
    "                'length_scales': [0.7, 0.8, 0.9, 1.0],\n",
    "                'noise_scales': [0.98],\n",
    "                'noise_scales_ws': [0.98],\n",
    "                'max_speakers': 600,\n",
    "                'phoneme_input': True,\n",
    "                             #             batch_size=200, slerp_weights = [0.8], length_scales=[0.8,0.9,1.0], #noise_scales=[0.98],max_speakers=600, phoneme_input=True)\n",
    "            }         \n",
    "        },\n",
    "        {\n",
    "            'input_path': '/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/piper-sample-generator/output/alexa/prepend',\n",
    "            'input_glob': '*.wav',\n",
    "            # 'impulse_paths': ['mit_rirs/'], \n",
    "            'impulse_paths': ['/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/notebooks/mixing/rir'], \n",
    "            'background_paths': ['/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/notebooks/mixing/background_clips'], \n",
    "            'augmentation_probabilities': {\n",
    "                    \"SevenBandParametricEQ\": 0.1,\n",
    "                    \"TanhDistortion\": 0.1,\n",
    "                    \"PitchShift\": 0.1,\n",
    "                    \"BandStopFilter\": 0.1,\n",
    "                    \"AddColorNoise\": 0.25,\n",
    "                    \"AddBackgroundNoise\": 0.75,\n",
    "                    \"Gain\": 1.0,\n",
    "                    \"RIR\": 0.5,\n",
    "                },\n",
    "            'augmented_duration_s': 3.99,\n",
    "            'max_start_time_from_right_s': None,\n",
    "            'max_jitter_s': 0.03,\n",
    "            'min_jitter_s': None,# 0.00,\n",
    "            'max_clip_duration_s': 3.0,   \n",
    "            'min_clip_duration_s': None,\n",
    "            'sampling_weight': 0.2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"clips\",  \n",
    "            'generate': False,          \n",
    "        },\n",
    "        {\n",
    "            'features_dir': 'training_sets/alexa/new_negatives',\n",
    "            'sampling_weight': 0.5,\n",
    "            'penalty_weight': 0.5,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': 'training_sets/speech_background_new',\n",
    "            'sampling_weight': 4,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': 'training_sets/dinner_party_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': 'training_sets/no_speech_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': 'training_sets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# config['features'] = [\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "#             'sampling_weight': 150,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#     ]\n",
    "# features_directory = '/Volumes/MachineLearning/multilingual_stuff/mswc_features/'\n",
    "# words = os.listdir(features_directory)\n",
    "\n",
    "# words = [x for x in words if not x.startswith('.')]\n",
    "\n",
    "# for index, word in enumerate(words):\n",
    "#     config['features'].append({\n",
    "#             'features_dir': os.path.join(features_directory, word),\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': True,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",        \n",
    "#     })\n",
    "\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [20000,20000,20000]#,20000,20000]#,15000]#,15000]#[15000,15000,15000]#[20000,20000]#,20000]#[20000,20000,20000]#,20000]#20000]#,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [1,1.5,2,2.5]#[1,3,5]#7.5,10]#[1,1.5,2]\n",
    "\n",
    "config['learning_rates'] = [0.001,0.0005,0.0002,0.0001]#[0.001, 0.0005,0.0005,0.0002]#,0.001] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 128\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 650   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['target_minimization'] = 1.0\n",
    "\n",
    "# config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "# config['maximization_metric'] = 'recall'\n",
    "\n",
    "config['minimization_metric'] = None  # Set to None to disable\n",
    "config['maximization_metric'] = 'recall_at_no_faph'\n",
    "\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "2024-05-24 13:28:40.348976: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-05-24 13:28:40.349003: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-05-24 13:28:40.349006: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-05-24 13:28:40.349037: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-24 13:28:40.349054: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 8\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 31\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(128, 100, 40)]             0         []                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (128, 100, 1, 40)            0         ['input_1[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stream (Stream)             (128, 100, 1, 40)            0         ['tf.expand_dims[0][0]']      \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (128, 96, 1, 40)             240       ['stream[0][0]']              \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (128, 96, 1, 64)             2560      ['depthwise_conv2d[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (128, 96, 1, 64)             256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (128, 96, 1, 64)             0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " stream_1 (Stream)           (128, 96, 1, 64)             0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)       [(128, 96, 1, 32),           0         ['stream_1[0][0]']            \n",
      "                              (128, 96, 1, 32)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep (StridedKeep)  (128, 96, 1, 32)             0         ['tf.split[0][0]']            \n",
      "                                                                                                  \n",
      " strided_keep_1 (StridedKee  (128, 96, 1, 32)             0         ['tf.split[0][1]']            \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (128, 92, 1, 32)             192       ['strided_keep[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (128, 88, 1, 32)             320       ['strided_keep_1[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop (StridedDrop)  (128, 88, 1, 32)             0         ['depthwise_conv2d_1[0][0]']  \n",
      "                                                                                                  \n",
      " strided_drop_1 (StridedDro  (128, 88, 1, 32)             0         ['depthwise_conv2d_2[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (128, 88, 1, 64)             0         ['strided_drop[0][0]',        \n",
      "                                                                     'strided_drop_1[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (128, 88, 1, 32)             2048      ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (128, 88, 1, 32)             128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (128, 88, 1, 32)             0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_2 (Stream)           (128, 88, 1, 32)             0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)     [(128, 88, 1, 16),           0         ['stream_2[0][0]']            \n",
      "                              (128, 88, 1, 16)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_2 (StridedKee  (128, 88, 1, 16)             0         ['tf.split_1[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_3 (StridedKee  (128, 88, 1, 16)             0         ['tf.split_1[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (128, 80, 1, 16)             160       ['strided_keep_2[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (128, 76, 1, 16)             224       ['strided_keep_3[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_2 (StridedDro  (128, 76, 1, 16)             0         ['depthwise_conv2d_3[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_3 (StridedDro  (128, 76, 1, 16)             0         ['depthwise_conv2d_4[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (128, 76, 1, 32)             0         ['strided_drop_2[0][0]',      \n",
      "                                                                     'strided_drop_3[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (128, 76, 1, 48)             1536      ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (128, 76, 1, 48)             192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (128, 76, 1, 48)             0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_3 (Stream)           (128, 76, 1, 48)             0         ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)     [(128, 76, 1, 24),           0         ['stream_3[0][0]']            \n",
      "                              (128, 76, 1, 24)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_4 (StridedKee  (128, 76, 1, 24)             0         ['tf.split_2[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_5 (StridedKee  (128, 76, 1, 24)             0         ['tf.split_2[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (128, 64, 1, 24)             336       ['strided_keep_4[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (128, 60, 1, 24)             432       ['strided_keep_5[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_4 (StridedDro  (128, 60, 1, 24)             0         ['depthwise_conv2d_5[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_5 (StridedDro  (128, 60, 1, 24)             0         ['depthwise_conv2d_6[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (128, 60, 1, 48)             0         ['strided_drop_4[0][0]',      \n",
      "                                                                     'strided_drop_5[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (128, 60, 1, 64)             3072      ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (128, 60, 1, 64)             256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (128, 60, 1, 64)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_4 (Stream)           (128, 60, 1, 64)             0         ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (Depthw  (128, 32, 1, 64)             1920      ['stream_4[0][0]']            \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (128, 32, 1, 64)             4096      ['depthwise_conv2d_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (128, 32, 1, 64)             256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (128, 32, 1, 64)             0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TF  (128, 32, 64, 1)             0         ['activation_4[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (128, 32, 1, 1)              0         ['tf.compat.v1.transpose[0][0]\n",
      " Pooling2D)                                                         ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (128, 32, 1, 1)              0         ['tf.compat.v1.transpose[0][0]\n",
      " D)                                                                 ']                            \n",
      "                                                                                                  \n",
      " stream_6 (Stream)           (128, 32, 1, 64)             0         ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (128, 32, 1, 2)              0         ['average_pooling2d[0][0]',   \n",
      "                                                                     'max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (128, 28, 1, 64)             0         ['stream_6[0][0]']            \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " stream_5 (Stream)           (128, 28, 1, 1)              10        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (128, 28, 1, 64)             0         ['tf.__operators__.getitem[0][\n",
      " da)                                                                0]',                          \n",
      "                                                                     'stream_5[0][0]']            \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (128, 1, 1, 64)              0         ['tf.math.multiply[0][0]']    \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (128, 64)                    0         ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)               (128, 1)                     65        ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18299 (71.48 KB)\n",
      "Trainable params: 17755 (69.36 KB)\n",
      "Non-trainable params: 544 (2.12 KB)\n",
      "__________________________________________________________________________________________________\n",
      "INFO:absl:None\n",
      "UserWarning:\n",
      "    MPS: The constant padding of more than 3 dimensions is not currently supported natively. It uses View Ops default implementation to run. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Pad.mm:472.)\n",
      "2024-05-24 13:28:43.846242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "INFO:absl:Step #500: rate 0.001000, accuracy 96.96%, recall 57.21%, precision 69.78%, cross entropy 0.120224\n",
      "INFO:absl:Step 500 (nonstreaming): Validation: recall at no faph = 60.168, accuracy = 90.15%, recall = 79.17%, precision = 91.94%, fpr = 3.81%, fnr = 20.83%, ambient false positives = 16, estimated false positives per hour = 2.99921, loss = 0.26451, auc = 0.94770,, max_auc = 0.993996455\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 60.16845%; no faph cutoff is 0.84\n",
      "INFO:absl:Step #1000: rate 0.001000, accuracy 98.29%, recall 72.84%, precision 85.82%, cross entropy 0.054308\n",
      "INFO:absl:Step 1000 (nonstreaming): Validation: recall at no faph = 61.339, accuracy = 90.74%, recall = 88.02%, precision = 86.17%, fpr = 7.76%, fnr = 11.98%, ambient false positives = 170, estimated false positives per hour = 31.86664, loss = 0.22962, auc = 0.96562,, max_auc = 0.996687842\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 61.33936%; no faph cutoff is 0.97\n",
      "^Clidation Batch #3: Accuracy = 0.983; Recall = 0.727; Precision = 0.863; Loss = 0.0511; Mini-Batch #39\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/model_train_eval.py\", line 392, in <module>\n",
      "    train_model(config, model, data_processor, flags.restore_checkpoint)\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/model_train_eval.py\", line 117, in train_model\n",
      "    train.train(model, config, data_processor)\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/train.py\", line 280, in train\n",
      "    ) = data_processor.get_data(\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/data.py\", line 464, in get_data\n",
      "    spectrogram = spec_augment(\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/data.py\", line 57, in spec_augment\n",
      "    augmented_spectrogram = np.copy(spectrogram)\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/.venv/lib/python3.10/site-packages/numpy/lib/function_base.py\", line 962, in copy\n",
      "    return array(a, order=order, subok=subok, copy=True)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "mixednet \\\n",
    "--pointwise_filters \"64, 32, 48, 64, 64\" \\\n",
    "--repeat_in_block  \"1, 1, 1, 1, 1\" \\\n",
    "--mixconv_kernel_sizes \"[5], [5,9], [9,13], [13,17], [29]\" \\\n",
    "--residual_connection \"0,0,0,0,0\" \\\n",
    "--first_conv_filters 0\n",
    "# inception \\\n",
    "# --cnn1_filters '32' \\\n",
    "# --cnn1_kernel_sizes '5' \\\n",
    "# --cnn1_subspectral_groups '4' \\\n",
    "# --cnn2_filters1 '24,24,24' \\\n",
    "# --cnn2_filters2 '32,64,96' \\\n",
    "# --cnn2_kernel_sizes '3,5,5' \\\n",
    "# --cnn2_subspectral_groups '1,1,1' \\\n",
    "# --cnn2_dilation '1,1,1' \\\n",
    "# --dropout 0.8 \n",
    "\n",
    "# bc_wide_matchbox \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --dropout_final_layer 0.0 \\\n",
    "# --ds_filters '32, 24, 24, 24, 32, 32' \\\n",
    "# --ds_filters2 '32, 32, 32, 32, 32, 32' \\\n",
    "# --ds_repeat '1, 2, 2, 2, 1, 0' \\\n",
    "# --ds_residual '0, 0, 0, 0, 0, 0' \\\n",
    "# --ds_kernel_size '5, 7, 9, 11, 19, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_padding \"'valid','valid','valid','valid','valid','valid'\" \\\n",
    "# --ds_pool '1,1,1,1,1,1' \\\n",
    "# --max_pool '1' \\\n",
    "# --freq_stride '1,2,1,2,1,1' \\\n",
    "# --first_conv_filters 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "[2, 1.5, 0.2, 0.2]\n",
      "[0.99, 0.97, 0.97, 0.9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "false_accepts_per_hour = [2, 1.5, 0.2, 0.2, 0, 0]\n",
    "# false_rejects = [0.03, 0.03, 0.10, 0.2, 0.3, 0.5]\n",
    "recall_at_cutoff = [0.99, 0.97, 0.97, 0.9, 0.85, 0.75]\n",
    "\n",
    "no_faph_cutoff_index = false_accepts_per_hour.index(0)\n",
    "print(no_faph_cutoff_index)\n",
    "\n",
    "# x_coordinates = [0]\n",
    "# y_coordinates = [recall_at_cutoff[no_faph_cutoff_index]]\n",
    "\n",
    "# for index in reversed(range(no_faph_cutoff_index)):\n",
    "#     x = false_accepts_per_hour[index]\n",
    "#     y = recall_at_cutoff[index]\n",
    "#     if false_accepts_per_hour[index] > 10:\n",
    "#         # we only care about faph rates up to 10\n",
    "#         break\n",
    "    \n",
    "    \n",
    "#     # if x == x_coordinates[-1]:\n",
    "#     #     # same faph as previous test, so go onto the next cutoff\n",
    "#     #     continue\n",
    "#     # else:\n",
    "#     #     # new faph, so add previous one and move on\n",
    "#     #     x_coordinates.append(false_accepts_per_hour[index])\n",
    "#     #     y_coordinates.append(recall_at_cutoff[index])\n",
    "# print(x_coordinates)\n",
    "# print(y_coordinates)\n",
    "\n",
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "for index in range(len(false_accepts_per_hour)):\n",
    "    x = false_accepts_per_hour[index]\n",
    "    y = recall_at_cutoff[index]\n",
    "    \n",
    "    if x > 5:\n",
    "        continue\n",
    "    \n",
    "    x_coordinates.append(x)\n",
    "    y_coordinates.append(y)\n",
    "\n",
    "\n",
    "x_coordinates = np.array(x_coordinates)\n",
    "y_coordinates = np.array(y_coordinates)\n",
    "\n",
    "x_coordinates_good = [x_coordinates[0]]\n",
    "y_coordinates_good = [y_coordinates[0]]\n",
    "for index in range(1,len(x_coordinates)):\n",
    "    print(index)\n",
    "    if x_coordinates[-1] == x_coordinates[index]:\n",
    "        continue\n",
    "    else:\n",
    "        x_coordinates_good.append(x_coordinates[index])\n",
    "        y_coordinates_good.append(y_coordinates[index])\n",
    "print(x_coordinates_good)\n",
    "print(y_coordinates_good)\n",
    "\n",
    "\n",
    "\n",
    "sum(predictions[testing_ground_truth[i : i + test_batch_size].nonzero()] > cutoff)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.75 0.5  0.29 0.27 0.13 0.  ]\n",
      "[1.   0.97 0.97 0.95 0.94 0.9  0.6 ]\n",
      "0.93555\n"
     ]
    }
   ],
   "source": [
    "total_false_positive_tests = 100\n",
    "false_positives_at_cutoff = np.array([75,50, 29, 27, 27, 13, 0, 0])\n",
    "recall_at_cutoff = np.array([0.97,0.97, 0.95, 0.94, 0.9, 0.9, 0.6, 0.4])\n",
    "\n",
    "false_positive_rates = false_positives_at_cutoff/total_false_positive_tests\n",
    "\n",
    "x_coordinates = [1.0]\n",
    "y_coordinates = [1.0]\n",
    "\n",
    "for index in range(0, len(false_positive_rates)):\n",
    "    if false_positive_rates[index] != x_coordinates[-1]:\n",
    "        x_coordinates.append(false_positive_rates[index])\n",
    "        y_coordinates.append(recall_at_cutoff[index])\n",
    "        \n",
    "x_coordinates = np.array(x_coordinates)\n",
    "y_coordinates = np.array(y_coordinates)\n",
    "print(x_coordinates)\n",
    "print(y_coordinates)\n",
    "# print(x_coordinates[(x_coordinates < 30).nonzero()])\n",
    "# print(y_coordinates[(x_coordinates < 30).nonzero()])\n",
    "\n",
    "print(np.trapz(np.flip(y_coordinates), np.flip(x_coordinates)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
