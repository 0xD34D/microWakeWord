{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['train_dir'] = '/Users/kahrendt/Documents/Hobbies/Machine_Learning/microwakeword/trained_models/okay_nabu_wide_matchbox'\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_positive',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_negative',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/english_speech_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/non_english_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background',\n",
    "            'sampling_weight': 2,\n",
    "            'penalty_weight': 3,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [500]#[30000, 30000,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [2, 3, 4, 5]\n",
    "\n",
    "config['learning_rates'] = [0.002, 0.001, 0.0005,0.0002] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 256\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [0]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [0]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [0]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [0]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1490   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "config['target_minimization'] = 0.5\n",
    "config['maximization_metric'] = 'recall'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 4398873 spectrograms representing 12650.1 hours of audio\n",
      "INFO:absl:validation mode has 19909 spectrograms representing 27.5 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 36543 spectrograms representing 36.6 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "2024-03-17 20:07:25.865728: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-03-17 20:07:25.865761: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-03-17 20:07:25.865772: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-03-17 20:07:25.865805: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-17 20:07:25.865819: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 0\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 74\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_conv2d_18_conv2d_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to /Users/kahrendt/Documents/Hobbies/Machine_Learning/microwakeword/trained_models/okay_nabu_wide_matchbox/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "2024-03-17 20:07:31.399063: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-03-17 20:07:31.399083: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-03-17 20:07:31.399598: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /Users/kahrendt/Documents/Hobbies/Machine_Learning/microwakeword/trained_models/okay_nabu_wide_matchbox/stream_state_internal\n",
      "2024-03-17 20:07:31.405330: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-03-17 20:07:31.405347: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /Users/kahrendt/Documents/Hobbies/Machine_Learning/microwakeword/trained_models/okay_nabu_wide_matchbox/stream_state_internal\n",
      "2024-03-17 20:07:31.415035: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-03-17 20:07:31.421103: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-03-17 20:07:31.556687: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /Users/kahrendt/Documents/Hobbies/Machine_Learning/microwakeword/trained_models/okay_nabu_wide_matchbox/stream_state_internal\n",
      "2024-03-17 20:07:31.606900: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 207300 microseconds.\n",
      "2024-03-17 20:07:31.650172: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-17 20:07:31.839884: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839906: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839908: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839910: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839912: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839914: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839916: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839919: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839921: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839923: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839925: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839927: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839937: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839939: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.839940: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840093: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840096: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840097: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840099: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840101: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840103: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840105: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840107: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-03-17 20:07:31.840240: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 72, Total Ops 200, % non-converted = 36.00 %\n",
      " * 71 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   71 occurrences  (f32: 59, i32: 12)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 15)\n",
      "  (f32: 19)\n",
      "  (f32: 12)\n",
      "  (f32: 1)\n",
      "  (f32: 12)\n",
      "  (f32: 2)\n",
      "  (f32: 12)\n",
      "  (: 24)\n",
      "2024-03-17 20:07:31.841057: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.040 M  ops, equivalently 0.020 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-03-17 20:08:18.353509: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.040 M  ops, equivalently 0.020 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing set\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.98002; recall = 0.937282; precision = 0.99262; fpr = 0.00280112; fnr = 0.0627178 (1000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984008; recall = 0.952899; precision = 0.988722; fpr = 0.00414079; fnr = 0.0471014 (2000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.983339; recall = 0.959707; precision = 0.978829; fpr = 0.00779102; fnr = 0.040293 (3000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.982754; recall = 0.960332; precision = 0.975633; fpr = 0.00891327; fnr = 0.0396679 (4000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.983603; recall = 0.962127; precision = 0.977794; fpr = 0.00826902; fnr = 0.0378733 (5000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.985002; recall = 0.965392; precision = 0.979667; fpr = 0.00757924; fnr = 0.0346084 (6000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984574; recall = 0.96395; precision = 0.979299; fpr = 0.0076666; fnr = 0.0360502 (7000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984627; recall = 0.96517; precision = 0.97817; fpr = 0.00807699; fnr = 0.0348304 (8000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984446; recall = 0.965292; precision = 0.977263; fpr = 0.00839438; fnr = 0.034708 (9000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984802; recall = 0.966423; precision = 0.977843; fpr = 0.00826332; fnr = 0.0335766 (10000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984729; recall = 0.967806; precision = 0.97623; fpr = 0.00888833; fnr = 0.0321938 (11000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984751; recall = 0.967467; precision = 0.976673; fpr = 0.0087236; fnr = 0.0325327 (12000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984617; recall = 0.966835; precision = 0.976718; fpr = 0.00868368; fnr = 0.0331647 (13000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984573; recall = 0.966571; precision = 0.976775; fpr = 0.0086512; fnr = 0.0334291 (14000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984734; recall = 0.967647; precision = 0.97602; fpr = 0.00888197; fnr = 0.0323529 (15000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984563; recall = 0.967349; precision = 0.975649; fpr = 0.00901133; fnr = 0.0326512 (16000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984354; recall = 0.965995; precision = 0.976144; fpr = 0.00880168; fnr = 0.0340048 (17000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984445; recall = 0.967253; precision = 0.975237; fpr = 0.00914983; fnr = 0.0327466 (18000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984422; recall = 0.967742; precision = 0.974898; fpr = 0.0093316; fnr = 0.0322581 (19000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984251; recall = 0.967653; precision = 0.974278; fpr = 0.0095467; fnr = 0.032347 (20000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984382; recall = 0.968373; precision = 0.974161; fpr = 0.00962168; fnr = 0.0316268 (21000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984546; recall = 0.968943; precision = 0.974148; fpr = 0.00961779; fnr = 0.0310569 (22000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.98474; recall = 0.969489; precision = 0.974314; fpr = 0.00955737; fnr = 0.0305112 (23000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984917; recall = 0.969674; precision = 0.97475; fpr = 0.00938645; fnr = 0.0303262 (24000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984921; recall = 0.969764; precision = 0.974771; fpr = 0.0094018; fnr = 0.0302363 (25000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984462; recall = 0.968697; precision = 0.974192; fpr = 0.00962505; fnr = 0.0313029 (26000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984778; recall = 0.969212; precision = 0.974898; fpr = 0.00937436; fnr = 0.030788 (27000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984715; recall = 0.969408; precision = 0.974504; fpr = 0.00953223; fnr = 0.0305922 (28000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984621; recall = 0.968762; precision = 0.974679; fpr = 0.00943396; fnr = 0.0312381 (29000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984534; recall = 0.9688; precision = 0.974283; fpr = 0.00957486; fnr = 0.0312003 (30000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984549; recall = 0.969112; precision = 0.974069; fpr = 0.00966698; fnr = 0.0308876 (31000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984594; recall = 0.969056; precision = 0.974098; fpr = 0.00961043; fnr = 0.0309444 (32000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984455; recall = 0.968691; precision = 0.974009; fpr = 0.00965621; fnr = 0.0313092 (33000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984324; recall = 0.968463; precision = 0.973827; fpr = 0.00974052; fnr = 0.0315369 (34000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984315; recall = 0.968711; precision = 0.973515; fpr = 0.00985202; fnr = 0.0312894 (35000 out of 36543)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.984195; recall = 0.968228; precision = 0.973682; fpr = 0.00981628; fnr = 0.0317719 (36000 out of 36543)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 98.4320%; recall = 96.8408%; precision = 97.3976%; fpr = 0.9709%; fnr = 3.1592%; (N=36543.0)\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 20.0; false accepts per hour = 3.749\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 0 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"last_weights\" \\\n",
    "wide_matchbox \\\n",
    "--activation 'relu' \\\n",
    "--dropout 0.0 \\\n",
    "--ds_filters '40, 20, 20, 20, 40, 40' \\\n",
    "--ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "--ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "--ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# ds_tc_resnet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --ds_filters '96, 48, 48, 48, 96, 96' \\\n",
    "# --ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# inception \\\n",
    "# --cnn1_filters '32' \\\n",
    "# --cnn1_kernel_sizes '5' \\\n",
    "# --cnn1_subspectral_groups '1' \\\n",
    "# --cnn2_filters1 '24,24,24' \\\n",
    "# --cnn2_filters2 '32,64,96' \\\n",
    "# --cnn2_kernel_sizes '3,5,5' \\\n",
    "# --cnn2_subspectral_groups '1,1,1' \\\n",
    "# --cnn2_dilation '1,1,1' \\\n",
    "# --dropout 0.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
