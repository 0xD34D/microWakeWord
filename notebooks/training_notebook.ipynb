{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from microwakeword.feature_generation import ClipsHandler\n",
    "\n",
    "config = {}\n",
    "\n",
    "# config['train_dir'] = 'trained_models/test_new_formulation'\n",
    "config['train_dir'] = 'trained_models/changes_revert_test'\n",
    "\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/alexa/positive_min_end_jitter',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",\n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/piper-sample-generator/output/alexa',\n",
    "            'input_glob': '*2/*.wav',\n",
    "            # 'impulse_paths': ['mit_rirs/'], \n",
    "            'impulse_paths': ['/Volumes/MachineLearning/audio_samples/background_noise_samples/wav_16k/bird_rir_all_channels_16k'], \n",
    "            'background_paths': ['/Volumes/MachineLearning/audio_samples/background_noise_samples/background_clips_for_mixing'], \n",
    "            'augmentation_probabilities': {\n",
    "                    \"SevenBandParametricEQ\": 0.1,\n",
    "                    \"TanhDistortion\": 0.1,\n",
    "                    \"PitchShift\": 0.1,\n",
    "                    \"BandStopFilter\": 0.1,\n",
    "                    \"AddColorNoise\": 0.25,\n",
    "                    \"AddBackgroundNoise\": 0.75,\n",
    "                    \"Gain\": 1.0,\n",
    "                    \"RIR\": 0.5,\n",
    "                },\n",
    "            'augmented_duration_s': 2.99,\n",
    "            'max_start_time_from_right_s': None,\n",
    "            'max_jitter_s': 0.2,\n",
    "            'min_jitter_s': 0.05,\n",
    "            'max_clip_duration_s': 1.37,   \n",
    "            'min_clip_duration_s': None,\n",
    "            'sampling_weight': 0.5,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"clips\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/alexa/old_negative',\n",
    "            'sampling_weight': 0.5,\n",
    "            'penalty_weight': 0.5,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/speech_background_new',\n",
    "            'sampling_weight': 4,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background_new',\n",
    "            'sampling_weight': 3,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "            'sampling_weight': 0.0,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'split',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "# config['features'] = [\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "#             'sampling_weight': 150,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#     ]\n",
    "# features_directory = '/Volumes/MachineLearning/multilingual_stuff/mswc_features/'\n",
    "# words = os.listdir(features_directory)\n",
    "\n",
    "# words = [x for x in words if not x.startswith('.')]\n",
    "\n",
    "# for index, word in enumerate(words):\n",
    "#     config['features'].append({\n",
    "#             'features_dir': os.path.join(features_directory, word),\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': True,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",        \n",
    "#     })\n",
    "\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [500]#[20000,20000,20000]#,15000]#,15000]#[15000,15000,15000]#[20000,20000]#,20000]#[20000,20000,20000]#,20000]#20000]#,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [1,3,5]#7.5,10]#[1,1.5,2]\n",
    "\n",
    "config['learning_rates'] = [0.001,0.0005,0.0002]#[0.001, 0.0005,0.0005,0.0002]#,0.001] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 128\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [10]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [0]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [4]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 210#650   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['target_minimization'] = 1.0\n",
    "\n",
    "# config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "# config['maximization_metric'] = 'recall'\n",
    "\n",
    "config['minimization_metric'] = None  # Set to None to disable\n",
    "config['maximization_metric'] = 'recall_at_no_faph'\n",
    "\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 1146843 spectrograms representing 1417.5 hours of audio\n",
      "INFO:absl:validation mode has 17358 spectrograms representing 19.2 hours of audio\n",
      "INFO:absl:validation_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "INFO:absl:testing mode has 17359 spectrograms representing 19.2 hours of audio\n",
      "INFO:absl:testing_ambient mode has 10 spectrograms representing 5.3 hours of audio\n",
      "2024-05-16 10:42:17.018531: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-05-16 10:42:17.018561: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-05-16 10:42:17.018567: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-05-16 10:42:17.018604: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-16 10:42:17.018620: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 8\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(128, 78, 40)]              0         []                            \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (128, 78, 1, 40)             0         ['input_1[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " stream (Stream)             (128, 78, 1, 40)             0         ['tf.expand_dims[0][0]']      \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (128, 74, 1, 40)             240       ['stream[0][0]']              \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (128, 74, 1, 64)             2560      ['depthwise_conv2d[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (128, 74, 1, 64)             256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (128, 74, 1, 64)             0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " stream_1 (Stream)           (128, 74, 1, 64)             0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)       [(128, 74, 1, 32),           0         ['stream_1[0][0]']            \n",
      "                              (128, 74, 1, 32)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep (StridedKeep)  (128, 74, 1, 32)             0         ['tf.split[0][0]']            \n",
      "                                                                                                  \n",
      " strided_keep_1 (StridedKee  (128, 74, 1, 32)             0         ['tf.split[0][1]']            \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (128, 70, 1, 32)             192       ['strided_keep[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (128, 66, 1, 32)             320       ['strided_keep_1[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop (StridedDrop)  (128, 66, 1, 32)             0         ['depthwise_conv2d_1[0][0]']  \n",
      "                                                                                                  \n",
      " strided_drop_1 (StridedDro  (128, 66, 1, 32)             0         ['depthwise_conv2d_2[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (128, 66, 1, 64)             0         ['strided_drop[0][0]',        \n",
      "                                                                     'strided_drop_1[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (128, 66, 1, 32)             2048      ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (128, 66, 1, 32)             128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (128, 66, 1, 32)             0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_2 (Stream)           (128, 66, 1, 32)             0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)     [(128, 66, 1, 16),           0         ['stream_2[0][0]']            \n",
      "                              (128, 66, 1, 16)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_2 (StridedKee  (128, 66, 1, 16)             0         ['tf.split_1[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_3 (StridedKee  (128, 66, 1, 16)             0         ['tf.split_1[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (128, 58, 1, 16)             160       ['strided_keep_2[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (128, 54, 1, 16)             224       ['strided_keep_3[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_2 (StridedDro  (128, 54, 1, 16)             0         ['depthwise_conv2d_3[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_3 (StridedDro  (128, 54, 1, 16)             0         ['depthwise_conv2d_4[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (128, 54, 1, 32)             0         ['strided_drop_2[0][0]',      \n",
      "                                                                     'strided_drop_3[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (128, 54, 1, 48)             1536      ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (128, 54, 1, 48)             192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (128, 54, 1, 48)             0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_3 (Stream)           (128, 54, 1, 48)             0         ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)     [(128, 54, 1, 24),           0         ['stream_3[0][0]']            \n",
      "                              (128, 54, 1, 24)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_4 (StridedKee  (128, 54, 1, 24)             0         ['tf.split_2[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_5 (StridedKee  (128, 54, 1, 24)             0         ['tf.split_2[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (128, 42, 1, 24)             336       ['strided_keep_4[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (128, 38, 1, 24)             432       ['strided_keep_5[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_4 (StridedDro  (128, 38, 1, 24)             0         ['depthwise_conv2d_5[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_5 (StridedDro  (128, 38, 1, 24)             0         ['depthwise_conv2d_6[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (128, 38, 1, 48)             0         ['strided_drop_4[0][0]',      \n",
      "                                                                     'strided_drop_5[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (128, 38, 1, 64)             3072      ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (128, 38, 1, 64)             256       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (128, 38, 1, 64)             0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_4 (Stream)           (128, 38, 1, 64)             0         ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " tf.split_3 (TFOpLambda)     [(128, 38, 1, 32),           0         ['stream_4[0][0]']            \n",
      "                              (128, 38, 1, 32)]                                                   \n",
      "                                                                                                  \n",
      " strided_keep_6 (StridedKee  (128, 38, 1, 32)             0         ['tf.split_3[0][0]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_keep_7 (StridedKee  (128, 38, 1, 32)             0         ['tf.split_3[0][1]']          \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (Depthw  (128, 22, 1, 32)             576       ['strided_keep_6[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (Depthw  (128, 10, 1, 32)             960       ['strided_keep_7[0][0]']      \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " strided_drop_6 (StridedDro  (128, 10, 1, 32)             0         ['depthwise_conv2d_7[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " strided_drop_7 (StridedDro  (128, 10, 1, 32)             0         ['depthwise_conv2d_8[0][0]']  \n",
      " p)                                                                                               \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (128, 10, 1, 64)             0         ['strided_drop_6[0][0]',      \n",
      "                                                                     'strided_drop_7[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (128, 10, 1, 64)             4096      ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (128, 10, 1, 64)             256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (128, 10, 1, 64)             0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " stream_5 (Stream)           (128, 1, 1, 64)              0         ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (128, 64)                    0         ['stream_5[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (128, 1)                     65        ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17905 (69.94 KB)\n",
      "Trainable params: 17361 (67.82 KB)\n",
      "Non-trainable params: 544 (2.12 KB)\n",
      "__________________________________________________________________________________________________\n",
      "INFO:absl:None\n",
      "2024-05-16 10:42:20.478118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "INFO:absl:Step #500: rate 0.001000, accuracy 97.68%, recall 75.45%, precision 74.29%, cross entropy 0.091859\n",
      "INFO:absl:Step 500 (nonstreaming): Validation: recall at no faph = 49.899, accuracy = 89.12%, recall = 77.39%, precision = 96.38%, fpr = 2.16%, fnr = 22.61%, ambient false positives = 6, estimated false positives per hour = 1.12470, loss = 0.26970, auc = 0.96806,\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 49.89866%; no faph cutoff is 0.86\n",
      "INFO:absl:Last weights on testing set: accuracy = 89.6595%; recall = 78.6110%; precision = 96.4842%; fpr = 2.1289%; fnr = 21.3890%; (N=17359.0)\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 8\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "INFO:absl:Saving nonstreaming model\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/changes_revert_test/non_stream/fingerprint.pb\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 8\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/changes_revert_test/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Testing nonstreaming model\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.911089; recall = 0.807229; precision = 0.973837; fpr = 0.0153584; fnr = 0.192771 (1000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.902049; recall = 0.786058; precision = 0.973214; fpr = 0.0153978; fnr = 0.213942 (2000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.903366; recall = 0.786699; precision = 0.972919; fpr = 0.0152715; fnr = 0.213301 (3000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.900525; recall = 0.781477; precision = 0.972139; fpr = 0.0157514; fnr = 0.218523 (4000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.89942; recall = 0.7805; precision = 0.972472; fpr = 0.0157588; fnr = 0.2195 (5000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.900183; recall = 0.784322; precision = 0.971893; fpr = 0.0163417; fnr = 0.215678 (6000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.898729; recall = 0.780412; precision = 0.970098; fpr = 0.0171107; fnr = 0.219588 (7000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.899388; recall = 0.784478; precision = 0.969384; fpr = 0.0178456; fnr = 0.215522 (8000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.899456; recall = 0.786205; precision = 0.96874; fpr = 0.0184014; fnr = 0.213795 (9000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.89911; recall = 0.786629; precision = 0.968194; fpr = 0.0188483; fnr = 0.213371 (10000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.896737; recall = 0.782458; precision = 0.965609; fpr = 0.0202448; fnr = 0.217542 (11000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.896759; recall = 0.783981; precision = 0.965032; fpr = 0.0207732; fnr = 0.216019 (12000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.89647; recall = 0.783509; precision = 0.965533; fpr = 0.020547; fnr = 0.216491 (13000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.896293; recall = 0.784003; precision = 0.964301; fpr = 0.0213003; fnr = 0.215997 (14000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.896607; recall = 0.786295; precision = 0.964498; fpr = 0.0214891; fnr = 0.213705 (15000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.897069; recall = 0.786731; precision = 0.96507; fpr = 0.0211145; fnr = 0.213269 (16000 out of 17359)\n",
      "INFO:absl:TensorFlow model on the testing set: accuracy = 0.896888; recall = 0.786256; precision = 0.965435; fpr = 0.0209145; fnr = 0.213744 (17000 out of 17359)\n",
      "INFO:absl:Final TensorFlow model on the testing set: accuracy = 89.6595%; recall = 78.6110%; precision = 96.4842%; fpr = 2.1289%; fnr = 21.3890%; (N=17359)\n",
      "INFO:absl:Converting nonstreaming model to TFLite\n",
      "2024-05-16 10:44:22.339678: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-16 10:44:22.339697: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-16 10:44:22.340171: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/changes_revert_test/non_stream\n",
      "2024-05-16 10:44:22.342970: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-16 10:44:22.342981: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/changes_revert_test/non_stream\n",
      "2024-05-16 10:44:22.347250: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-05-16 10:44:22.349906: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-16 10:44:22.407646: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/changes_revert_test/non_stream\n",
      "2024-05-16 10:44:22.431788: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 91617 microseconds.\n",
      "2024-05-16 10:44:22.451994: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 34, Total Ops 76, % non-converted = 44.74 %\n",
      " * 34 ARITH ops\n",
      "\n",
      "- arith.constant:   34 occurrences  (f32: 25, i32: 9)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 5)\n",
      "  (f32: 9)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 5)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 8)\n",
      "2024-05-16 10:44:22.513925: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 1.385 M  ops, equivalently 0.692 M  MACs\n",
      "INFO:absl:Testing the TFLite nonstreaming model on the testing set\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.9001; recall = 0.783721; precision = 0.979651; fpr = 0.0122592; fnr = 0.216279 (1000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896552; recall = 0.781401; precision = 0.961367; fpr = 0.0221654; fnr = 0.218599 (2000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896368; recall = 0.781075; precision = 0.962451; fpr = 0.0216648; fnr = 0.218925 (3000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896526; recall = 0.782922; precision = 0.960886; fpr = 0.0226689; fnr = 0.217078 (4000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895021; recall = 0.783452; precision = 0.961137; fpr = 0.0232155; fnr = 0.216548 (5000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.897517; recall = 0.789078; precision = 0.960501; fpr = 0.0236039; fnr = 0.210922 (6000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895872; recall = 0.784433; precision = 0.961826; fpr = 0.0227385; fnr = 0.215567 (7000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.892888; recall = 0.780236; precision = 0.959376; fpr = 0.0242897; fnr = 0.219764 (8000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.892345; recall = 0.781714; precision = 0.958174; fpr = 0.0253778; fnr = 0.218286 (9000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.894211; recall = 0.7843; precision = 0.95879; fpr = 0.0248307; fnr = 0.2157 (10000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895282; recall = 0.785177; precision = 0.960074; fpr = 0.0239521; fnr = 0.214823 (11000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895092; recall = 0.785392; precision = 0.960154; fpr = 0.0240301; fnr = 0.214608 (12000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896239; recall = 0.786751; precision = 0.961411; fpr = 0.0232279; fnr = 0.213249 (13000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896007; recall = 0.78622; precision = 0.961475; fpr = 0.0231866; fnr = 0.21378 (14000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896607; recall = 0.786558; precision = 0.962442; fpr = 0.0225486; fnr = 0.213442 (15000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896506; recall = 0.786355; precision = 0.96343; fpr = 0.0220652; fnr = 0.213645 (16000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896771; recall = 0.786199; precision = 0.963982; fpr = 0.021668; fnr = 0.213801 (17000 out of 17359)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 89.6711%; recall = 78.6650%; precision = 96.4546%; fpr = 2.1490%; fnr = 21.3350%; (N=17359.0)\n",
      "INFO:absl:Converting streaming model to TFLite\n",
      "2024-05-16 10:44:24.678916: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-16 10:44:24.678936: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-16 10:44:24.679095: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:44:24.682215: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-16 10:44:24.682226: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:44:24.689845: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-16 10:44:24.756368: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:44:24.781047: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 101952 microseconds.\n",
      "2024-05-16 10:44:24.909477: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909499: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909502: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909504: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909506: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909508: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909518: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909520: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909522: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909800: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909808: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:44:24.909810: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 55, Total Ops 142, % non-converted = 38.73 %\n",
      " * 54 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   54 occurrences  (f32: 31, i32: 23)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 5)\n",
      "  (f32: 9)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 5)\n",
      "  (f32: 6)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 14)\n",
      "  (: 12)\n",
      "2024-05-16 10:44:24.910521: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.034 M  ops, equivalently 0.017 M  MACs\n",
      "INFO:absl:Testing the TFLite streaming model on the testing set\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.9001; recall = 0.790754; precision = 0.958702; fpr = 0.0237288; fnr = 0.209246 (1000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896052; recall = 0.784104; precision = 0.962154; fpr = 0.0224525; fnr = 0.215896 (2000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.890037; recall = 0.772763; precision = 0.957802; fpr = 0.0247411; fnr = 0.227237 (3000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.890277; recall = 0.772781; precision = 0.959589; fpr = 0.0237992; fnr = 0.227219 (4000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895021; recall = 0.779524; precision = 0.963508; fpr = 0.0213719; fnr = 0.220476 (5000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895684; recall = 0.781077; precision = 0.964321; fpr = 0.0210072; fnr = 0.218923 (6000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895872; recall = 0.783446; precision = 0.96344; fpr = 0.0217768; fnr = 0.216554 (7000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895013; recall = 0.782377; precision = 0.962182; fpr = 0.0225157; fnr = 0.217623 (8000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.893345; recall = 0.779265; precision = 0.961464; fpr = 0.0229243; fnr = 0.220735 (9000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.894411; recall = 0.781625; precision = 0.962576; fpr = 0.0224114; fnr = 0.218375 (10000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895919; recall = 0.784079; precision = 0.964211; fpr = 0.0214918; fnr = 0.215921 (11000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896509; recall = 0.78535; precision = 0.964079; fpr = 0.0215661; fnr = 0.21465 (12000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896546; recall = 0.786284; precision = 0.962897; fpr = 0.0222994; fnr = 0.213716 (13000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.89665; recall = 0.786195; precision = 0.963483; fpr = 0.0219576; fnr = 0.213805 (14000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.89614; recall = 0.785435; precision = 0.963867; fpr = 0.0218199; fnr = 0.214565 (15000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896444; recall = 0.786311; precision = 0.964234; fpr = 0.0216823; fnr = 0.213689 (16000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895594; recall = 0.784681; precision = 0.964116; fpr = 0.0217614; fnr = 0.215319 (17000 out of 17359)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 89.6423%; recall = 78.6110%; precision = 96.4363%; fpr = 2.1591%; fnr = 21.3890%; (N=17359.0)\n",
      "INFO:absl:Testing the TFLite streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 6.0; false accepts per hour = 1.125\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "2024-05-16 10:45:04.335102: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-16 10:45:04.335121: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-16 10:45:04.335254: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:45:04.338965: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-16 10:45:04.338984: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:45:04.346493: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-16 10:45:04.408136: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/changes_revert_test/stream_state_internal\n",
      "2024-05-16 10:45:04.436889: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 101634 microseconds.\n",
      "2024-05-16 10:45:04.568539: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568562: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568565: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568567: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568569: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568571: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568580: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568582: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568584: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568626: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568631: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-05-16 10:45:04.568633: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 142, % non-converted = 42.25 %\n",
      " * 59 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   59 occurrences  (f32: 36, i32: 23)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 5)\n",
      "  (f32: 9)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 6)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 14)\n",
      "  (: 12)\n",
      "2024-05-16 10:45:04.569313: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.034 M  ops, equivalently 0.017 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-05-16 10:45:19.837033: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.034 M  ops, equivalently 0.017 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing set\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.878122; recall = 0.752735; precision = 0.974504; fpr = 0.0165441; fnr = 0.247265 (1000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.888556; recall = 0.76731; precision = 0.974063; fpr = 0.0160714; fnr = 0.23269 (2000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.892369; recall = 0.771341; precision = 0.977778; fpr = 0.0136175; fnr = 0.228659 (3000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.896026; recall = 0.779243; precision = 0.977698; fpr = 0.013735; fnr = 0.220757 (4000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895421; recall = 0.778962; precision = 0.973364; fpr = 0.0161801; fnr = 0.221038 (5000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.897684; recall = 0.787283; precision = 0.970546; fpr = 0.0182032; fnr = 0.212717 (6000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.897872; recall = 0.78796; precision = 0.966762; fpr = 0.0201945; fnr = 0.21204 (7000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.898263; recall = 0.787852; precision = 0.967219; fpr = 0.0198128; fnr = 0.212148 (8000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.8979; recall = 0.785976; precision = 0.967472; fpr = 0.0195018; fnr = 0.214024 (9000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.89821; recall = 0.786472; precision = 0.967527; fpr = 0.0194512; fnr = 0.213528 (10000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.898646; recall = 0.788408; precision = 0.96808; fpr = 0.0193405; fnr = 0.211592 (11000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.899092; recall = 0.790556; precision = 0.966004; fpr = 0.0205887; fnr = 0.209444 (12000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.897316; recall = 0.786838; precision = 0.965395; fpr = 0.0208835; fnr = 0.213162 (13000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.897222; recall = 0.786532; precision = 0.964691; fpr = 0.0212132; fnr = 0.213468 (14000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.89614; recall = 0.784427; precision = 0.964926; fpr = 0.0211186; fnr = 0.215573 (15000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895694; recall = 0.783717; precision = 0.965368; fpr = 0.0209333; fnr = 0.216283 (16000 out of 17359)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.895124; recall = 0.781908; precision = 0.966145; fpr = 0.0204354; fnr = 0.218092 (17000 out of 17359)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 89.5328%; recall = 78.2192%; precision = 96.5799%; fpr = 2.0586%; fnr = 21.7808%; (N=17359.0)\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "INFO:absl:Final TFLite model on the testing_ambient set: false accepts = 6.0; false accepts per hour = 1.125\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 1 \\\n",
    "--test_tflite_nonstreaming 1 \\\n",
    "--test_tflite_streaming 1 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "mixednet \\\n",
    "--pointwise_filters \"64, 32, 48, 64, 64\" \\\n",
    "--repeat_in_block  \"1, 1, 1, 1, 1\" \\\n",
    "--mixconv_kernel_sizes \"[5], [5,9], [9,13], [13,17], [17,29]\" \\\n",
    "--residual_connection \"0,0,0,0,0\" \\\n",
    "--first_conv_filters 0\n",
    "# mixednet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --dropout_final_layer 0.0 \\\n",
    "# --ds_filters '32, 40, 40, 40, 48, 64' \\\n",
    "# --ds_filters2 '32, 32, 32, 32, 32, 32' \\\n",
    "# --ds_repeat '1, 2, 2, 2, 1, 0' \\\n",
    "# --ds_residual '0, 0, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '5, 7, 9, 11, 19, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_padding \"'valid','valid','valid','valid','valid','valid'\" \\\n",
    "# --ds_pool '1,1,1,1,1,1' \\\n",
    "# --max_pool '0' \\\n",
    "# --first_conv_filters 32\n",
    "# bc_wide_matchbox \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --dropout_final_layer 0.0 \\\n",
    "# --ds_filters '32, 24, 24, 24, 32, 32' \\\n",
    "# --ds_filters2 '32, 32, 32, 32, 32, 32' \\\n",
    "# --ds_repeat '1, 2, 2, 2, 1, 0' \\\n",
    "# --ds_residual '0, 0, 0, 0, 0, 0' \\\n",
    "# --ds_kernel_size '5, 7, 9, 11, 19, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_padding \"'valid','valid','valid','valid','valid','valid'\" \\\n",
    "# --ds_pool '1,1,1,1,1,1' \\\n",
    "# --max_pool '1' \\\n",
    "# --freq_stride '1,2,1,2,1,1' \\\n",
    "# --first_conv_filters 24\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
