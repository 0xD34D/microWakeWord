{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install tensorflow\n",
    "!pip install mmap_ninja\n",
    "!pip install pyyaml\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config['train_dir'] = 'trained_models/vad'\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "# config['features'] = [\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_positive',\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': True,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",\n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/okay_nabu/generated_negative',\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'truncate_start',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/english_speech_background',\n",
    "#             'sampling_weight': 2,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/non_english_speech_background',\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/dinner_party_background',\n",
    "#             'sampling_weight': 2,\n",
    "#             'penalty_weight': 3,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "#             'sampling_weight': 1,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'random',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#         {\n",
    "#             'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/ambient_background',\n",
    "#             'sampling_weight': 0.0,\n",
    "#             'penalty_weight': 1,\n",
    "#             'truth': False,\n",
    "#             'truncation_strategy': 'split',\n",
    "#             'type': \"mmap\",            \n",
    "#         },\n",
    "#     ]\n",
    "\n",
    "config['features'] = [\n",
    "        {\n",
    "            'features_dir': '/Volumes/MachineLearning/training_data/negative_datasets/no_speech_background',\n",
    "            'sampling_weight': 150,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': False,\n",
    "            'truncation_strategy': 'random',\n",
    "            'type': \"mmap\",            \n",
    "        },\n",
    "    ]\n",
    "features_directory = '/Volumes/MachineLearning/multilingual_stuff/mswc_features/'\n",
    "words = os.listdir(features_directory)\n",
    "\n",
    "words = [x for x in words if not x.startswith('.')]\n",
    "\n",
    "for index, word in enumerate(words):\n",
    "    config['features'].append({\n",
    "            'features_dir': os.path.join(features_directory, word),\n",
    "            'sampling_weight': 1,\n",
    "            'penalty_weight': 1,\n",
    "            'truth': True,\n",
    "            'truncation_strategy': 'truncate_start',\n",
    "            'type': \"mmap\",        \n",
    "    })\n",
    "\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config['training_steps'] = [20000, 20000,20000,20000]        \n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]               \n",
    "config[\"negative_class_weight\"] = [1]#[2, 3, 4, 5]\n",
    "\n",
    "config['learning_rates'] = [0.002, 0.001, 0.0005,0.0002] # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config['batch_size'] = 256\n",
    "\n",
    "config['mix_up_augmentation_prob'] =  [0]       # Probability of applying MixUp augmentation - list that corresponds to training steps\n",
    "config['freq_mix_augmentation_prob'] = [0]      # Probability of applying FreqMix augmentation - list that corresponds to training steps\n",
    "config['time_mask_max_size'] = [5]              # SpecAugment - list that corresponds to training steps\n",
    "config['time_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_max_size'] = [7]              # SpecAugment - list that corresponds to training steps\n",
    "config['freq_mask_count'] = [2]                 # SpecAugment - list that corresponds to training steps\n",
    "config['eval_step_interval'] = 500              # Test the validation sets after every this many steps\n",
    "\n",
    "config['clip_duration_ms'] = 1090   # Maximum length of wake word that the streaming model will accept\n",
    "# config['window_stride_ms'] = 20     # Fixed setting for default feature generator\n",
    "# config['window_size_ms'] = 30       # Fixed setting for default feature generator\n",
    "# config['sample_rate'] = 16000       # Fixed setting for default feature generator\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config['minimization_metric'] = 'ambient_false_positives_per_hour'  # Set to None to disable\n",
    "config['target_minimization'] = 0.25\n",
    "config['maximization_metric'] = 'recall'\n",
    "config['binary_classification'] = False\n",
    "\n",
    "with open(os.path.join('training_parameters.yaml'), 'w') as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Loading and analyzing data sets.\n",
      "INFO:absl:training mode has 3835622 spectrograms representing 5377.8 hours of audio\n",
      "INFO:absl:validation mode has 38820 spectrograms representing 58.2 hours of audio\n",
      "INFO:absl:validation_ambient mode has 0 spectrograms representing 0.0 hours of audio\n",
      "INFO:absl:testing mode has 33787 spectrograms representing 43.6 hours of audio\n",
      "INFO:absl:testing_ambient mode has 0 spectrograms representing 0.0 hours of audio\n",
      "2024-04-13 20:23:11.420826: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2024-04-13 20:23:11.420845: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-13 20:23:11.420853: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-13 20:23:11.420882: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-13 20:23:11.420895: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 12\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 16\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 28\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 0\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 54\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to model_conv2d_18_conv2d_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n",
      "INFO:absl:Writing fingerprint to trained_models/vad/stream_state_internal/fingerprint.pb\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "2024-04-13 20:23:16.317138: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-04-13 20:23:16.317157: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-04-13 20:23:16.317764: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/vad/stream_state_internal\n",
      "2024-04-13 20:23:16.324194: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-13 20:23:16.324215: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: trained_models/vad/stream_state_internal\n",
      "2024-04-13 20:23:16.333606: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-13 20:23:16.339250: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-04-13 20:23:16.465300: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: trained_models/vad/stream_state_internal\n",
      "2024-04-13 20:23:16.512690: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 194927 microseconds.\n",
      "2024-04-13 20:23:16.553179: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-13 20:23:16.743893: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743915: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743918: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743921: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743923: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743928: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743930: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743932: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743934: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743968: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743971: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743973: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743984: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743986: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743988: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743990: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.743992: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744168: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744173: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744176: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744178: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744180: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744182: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "2024-04-13 20:23:16.744183: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 72, Total Ops 200, % non-converted = 36.00 %\n",
      " * 71 ARITH ops, 1 TF_SAVED_MODEL ops\n",
      "\n",
      "- arith.constant:   71 occurrences  (f32: 59, i32: 12)\n",
      "\n",
      "\n",
      "\n",
      "- tf_saved_model.session_initializer:    1 occurrences\n",
      "\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 15)\n",
      "  (f32: 19)\n",
      "  (f32: 12)\n",
      "  (f32: 1)\n",
      "  (f32: 12)\n",
      "  (f32: 2)\n",
      "  (f32: 12)\n",
      "  (: 24)\n",
      "2024-04-13 20:23:16.745158: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.039 M  ops, equivalently 0.019 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2024-04-13 20:23:52.763792: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 0.039 M  ops, equivalently 0.019 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing set\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing TFLite model on the testing set\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992008; recall = 0.992248; precision = 0.998885; fpr = 0.0102041; fnr = 0.00775194 (1000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.993003; recall = 0.992733; precision = 0.999437; fpr = 0.00471698; fnr = 0.00726663 (2000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992669; recall = 0.992481; precision = 0.999243; fpr = 0.0058651; fnr = 0.0075188 (3000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.993252; recall = 0.99293; precision = 0.999431; fpr = 0.00430108; fnr = 0.00707014 (4000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.991602; recall = 0.991874; precision = 0.998636; fpr = 0.0105079; fnr = 0.00812641 (5000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992335; recall = 0.992497; precision = 0.998867; fpr = 0.00895522; fnr = 0.00750328 (6000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992287; recall = 0.992451; precision = 0.998868; fpr = 0.00903226; fnr = 0.00754899 (7000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992001; recall = 0.991993; precision = 0.99901; fpr = 0.00793651; fnr = 0.00800674 (8000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992445; recall = 0.992377; precision = 0.999119; fpr = 0.00700701; fnr = 0.00762309 (9000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992501; recall = 0.992359; precision = 0.999208; fpr = 0.00635209; fnr = 0.00764131 (10000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992455; recall = 0.992335; precision = 0.999177; fpr = 0.00657895; fnr = 0.00766479 (11000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992667; recall = 0.99251; precision = 0.999246; fpr = 0.00606061; fnr = 0.00748994 (12000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992616; recall = 0.992403; precision = 0.999305; fpr = 0.00564175; fnr = 0.00759734 (13000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992572; recall = 0.992456; precision = 0.999192; fpr = 0.00648929; fnr = 0.00754414 (14000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992934; recall = 0.992884; precision = 0.999171; fpr = 0.00666667; fnr = 0.00711557 (15000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992625; recall = 0.992482; precision = 0.999222; fpr = 0.00622172; fnr = 0.00751774 (16000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992824; recall = 0.992727; precision = 0.999201; fpr = 0.00639318; fnr = 0.00727321 (17000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992667; recall = 0.992572; precision = 0.999183; fpr = 0.00656234; fnr = 0.00742821 (18000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992737; recall = 0.992724; precision = 0.999107; fpr = 0.00715308; fnr = 0.00727638 (19000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.99275; recall = 0.992811; precision = 0.999039; fpr = 0.00774487; fnr = 0.00718859 (20000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.99281; recall = 0.992886; precision = 0.999031; fpr = 0.00780572; fnr = 0.0071142 (21000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992864; recall = 0.993; precision = 0.998972; fpr = 0.00823384; fnr = 0.0069998 (22000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992826; recall = 0.993059; precision = 0.998869; fpr = 0.00904088; fnr = 0.00694139 (23000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992834; recall = 0.993066; precision = 0.998869; fpr = 0.00903614; fnr = 0.00693371 (24000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.99276; recall = 0.993115; precision = 0.998733; fpr = 0.0100792; fnr = 0.00688476 (25000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992885; recall = 0.993206; precision = 0.998782; fpr = 0.00968523; fnr = 0.0067936 (26000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992852; recall = 0.993122; precision = 0.998826; fpr = 0.00929924; fnr = 0.00687787 (27000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992822; recall = 0.993049; precision = 0.998868; fpr = 0.00900032; fnr = 0.00695058 (28000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992759; recall = 0.992981; precision = 0.998869; fpr = 0.00902022; fnr = 0.00701931 (29000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992667; recall = 0.992914; precision = 0.998831; fpr = 0.00931211; fnr = 0.00708608 (30000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992613; recall = 0.992852; precision = 0.998832; fpr = 0.00929962; fnr = 0.00714804 (31000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992594; recall = 0.992824; precision = 0.998832; fpr = 0.00923852; fnr = 0.00717577 (32000 out of 33787)\n",
      "INFO:absl:TFLite model on the testing set: accuracy = 0.992576; recall = 0.992797; precision = 0.998832; fpr = 0.00917431; fnr = 0.00720259 (33000 out of 33787)\n",
      "INFO:absl:Final TFLite model on the testing set: accuracy = 99.2630%; recall = 99.2833%; precision = 99.8860%; fpr = 0.8978%; fnr = 0.7167%; (N=33787.0)\n",
      "INFO:absl:Testing the TFLite quantized streaming model on the testing_ambient set\n",
      "INFO:absl:Testing TFLite model on the testing_ambient set\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/model_train_eval.py\", line 401, in <module>\n",
      "    evaluate_model(\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/model_train_eval.py\", line 237, in evaluate_model\n",
      "    test.tflite_model_accuracy(\n",
      "  File \"/Users/kahrendt/Documents/Hobbies/Programming/Git-Repositories/microWakeWord/microwakeword/test.py\", line 276, in tflite_model_accuracy\n",
      "    faph=false_positives\n",
      "ZeroDivisionError: float division by zero\n"
     ]
    }
   ],
   "source": [
    "!python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 0 \\\n",
    "--restore_checkpoint 1 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"last_weights\" \\\n",
    "wide_matchbox \\\n",
    "--activation 'relu' \\\n",
    "--dropout 0.0 \\\n",
    "--ds_filters '40, 20, 20, 20, 40, 40' \\\n",
    "--ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "--ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "--ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "--ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# ds_tc_resnet \\\n",
    "# --activation 'relu' \\\n",
    "# --dropout 0.0 \\\n",
    "# --ds_filters '96, 48, 48, 48, 96, 96' \\\n",
    "# --ds_repeat '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_residual '0, 1, 1, 1, 0, 0' \\\n",
    "# --ds_kernel_size '11, 13, 15, 17, 29, 1' \\\n",
    "# --ds_stride '1, 1, 1, 1, 1, 1' \\\n",
    "# --ds_dilation '1, 1, 1, 1, 1, 1'\n",
    "# inception \\\n",
    "# --cnn1_filters '32' \\\n",
    "# --cnn1_kernel_sizes '5' \\\n",
    "# --cnn1_subspectral_groups '1' \\\n",
    "# --cnn2_filters1 '24,24,24' \\\n",
    "# --cnn2_filters2 '32,64,96' \\\n",
    "# --cnn2_kernel_sizes '3,5,5' \\\n",
    "# --cnn2_subspectral_groups '1,1,1' \\\n",
    "# --cnn2_dilation '1,1,1' \\\n",
    "# --dropout 0.8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
